{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","mount_file_id":"15R3RiPJr9ByaQXYZICAhyDb5aQ1hXRpW","authorship_tag":"ABX9TyPM6a7Dafpyks7q9c3Xui0g"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium","widgets":{"application/vnd.jupyter.widget-state+json":{"85eabe26c8a04200b1a1490d3a85a4c5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_63315f617d724721a71b13abe178badd","IPY_MODEL_5ee375653f4745f9b7855758e8c3d544","IPY_MODEL_4611b98519584683a24eab097b354343"],"layout":"IPY_MODEL_7bb0c2c9e2b540c28c464f6347595c66"}},"63315f617d724721a71b13abe178badd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7cae70d160514a6fa1d03dea280337d7","placeholder":"​","style":"IPY_MODEL_2eabc637d54c4c95af066c8e581411fa","value":"Downloading: 100%"}},"5ee375653f4745f9b7855758e8c3d544":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c2b250bd46a4e5fbffc8e380ebc78e6","max":481,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0c0bb26893dc4f5aa73fa9ae517f5d47","value":481}},"4611b98519584683a24eab097b354343":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3cde9ff3dd20475bb029798815bccc10","placeholder":"​","style":"IPY_MODEL_15873553bea548e088e92eed939fa918","value":" 481/481 [00:00&lt;00:00, 13.9kB/s]"}},"7bb0c2c9e2b540c28c464f6347595c66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7cae70d160514a6fa1d03dea280337d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2eabc637d54c4c95af066c8e581411fa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3c2b250bd46a4e5fbffc8e380ebc78e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c0bb26893dc4f5aa73fa9ae517f5d47":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3cde9ff3dd20475bb029798815bccc10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15873553bea548e088e92eed939fa918":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb28d90811c6455a9e31d5e4b22ec3cc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d9efc378bf6c4e60af8d7aa4eda79dcf","IPY_MODEL_4e2fc6030ecc4321afe1a3fcbbc82c14","IPY_MODEL_a6087d4725d241688d7086e25956db22"],"layout":"IPY_MODEL_21c76e5632f54ea3b560f1e9ddacd6ab"}},"d9efc378bf6c4e60af8d7aa4eda79dcf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c9a6ae3fa4b641b6bdce366b805bb8bf","placeholder":"​","style":"IPY_MODEL_6e4c786adb55432bb8e5a000945e62cc","value":"Downloading: 100%"}},"4e2fc6030ecc4321afe1a3fcbbc82c14":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_797b5aa770624c0b8b04b483debbc979","max":501200538,"min":0,"orientation":"horizontal","style":"IPY_MODEL_55ec46fe30884fed9cb96a280958b0ef","value":501200538}},"a6087d4725d241688d7086e25956db22":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7807582640864582ba06ce253cafe080","placeholder":"​","style":"IPY_MODEL_7d092d75a6714bedab5d0dd2cdb5bc8d","value":" 501M/501M [00:16&lt;00:00, 25.0MB/s]"}},"21c76e5632f54ea3b560f1e9ddacd6ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9a6ae3fa4b641b6bdce366b805bb8bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e4c786adb55432bb8e5a000945e62cc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"797b5aa770624c0b8b04b483debbc979":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55ec46fe30884fed9cb96a280958b0ef":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7807582640864582ba06ce253cafe080":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d092d75a6714bedab5d0dd2cdb5bc8d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"57e7fc0f5e9649eca4c332c15c25ee39":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b51ef49ce7b5419e94db80bbd7b511c2","IPY_MODEL_3561ced4fd3e4c6e964d51abb1fe0695","IPY_MODEL_1ad5fb59f5e945e79b45752d3cb5e448"],"layout":"IPY_MODEL_bade978927c8499ca106472424c10beb"}},"b51ef49ce7b5419e94db80bbd7b511c2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f0416985b234890926ba2005cdb9972","placeholder":"​","style":"IPY_MODEL_cf074472dfd54bcc8f448f372aff9386","value":"Downloading: 100%"}},"3561ced4fd3e4c6e964d51abb1fe0695":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5dedaa76b60b4ee3bcf3ee8992e81306","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4a9376a372784470810f668fc9fa1907","value":898823}},"1ad5fb59f5e945e79b45752d3cb5e448":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8a9eb5e08d041c1923b52fe5ab3bd37","placeholder":"​","style":"IPY_MODEL_b7e6f0b986dd47c4a7afaf2ef5fdc96a","value":" 899k/899k [00:00&lt;00:00, 1.69MB/s]"}},"bade978927c8499ca106472424c10beb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f0416985b234890926ba2005cdb9972":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf074472dfd54bcc8f448f372aff9386":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5dedaa76b60b4ee3bcf3ee8992e81306":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a9376a372784470810f668fc9fa1907":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b8a9eb5e08d041c1923b52fe5ab3bd37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7e6f0b986dd47c4a7afaf2ef5fdc96a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b683ed57da4744f8974b2f4be5c9e9b5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_aa8b021449874258b260f204839c39bc","IPY_MODEL_f113b15bf64a48fca5dbb2c16b0e16fa","IPY_MODEL_4b50b0229e364c4793ea4651844b2b2c"],"layout":"IPY_MODEL_63cf8c5168ee46d98fb63fadc32c8cb6"}},"aa8b021449874258b260f204839c39bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ea4bc8bc4e94063941348dc9e999bfe","placeholder":"​","style":"IPY_MODEL_0e8c166a22b74060867ee1baa450a0ce","value":"Downloading: 100%"}},"f113b15bf64a48fca5dbb2c16b0e16fa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f4f6030979b48b89ba28a426d799457","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dd2304f34218404b90e0236a5311b7cc","value":456318}},"4b50b0229e364c4793ea4651844b2b2c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_edeb354a9c3940bd9d9fba551e521f83","placeholder":"​","style":"IPY_MODEL_5a69212f561c4506b770eb18b94ac220","value":" 456k/456k [00:00&lt;00:00, 1.76MB/s]"}},"63cf8c5168ee46d98fb63fadc32c8cb6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ea4bc8bc4e94063941348dc9e999bfe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e8c166a22b74060867ee1baa450a0ce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8f4f6030979b48b89ba28a426d799457":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd2304f34218404b90e0236a5311b7cc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"edeb354a9c3940bd9d9fba551e521f83":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a69212f561c4506b770eb18b94ac220":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e55401ba967c401daf61c9aa93791e34":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_50bde6ee74784b5398a8566948387120","IPY_MODEL_2a0fc219ff1b4b3b8ad1b4d321f5020f","IPY_MODEL_a32fa5edd52047f89eab42270923030c"],"layout":"IPY_MODEL_4f56eb4b6c114ef7935fa093b340badf"}},"50bde6ee74784b5398a8566948387120":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c9e2735dba8b4414aff430f9b381107d","placeholder":"​","style":"IPY_MODEL_2185ca3833ed46f8a3ac42b62ab4323f","value":"100%"}},"2a0fc219ff1b4b3b8ad1b4d321f5020f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_94e96a483c814bfdb477f49a56055258","max":1633,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fed0c514f00d4ba5b3349c8490b0ecfc","value":1633}},"a32fa5edd52047f89eab42270923030c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aca4b7ec89bc44938003279addba3092","placeholder":"​","style":"IPY_MODEL_0b449adab27c4ffda3f4262c06fc38aa","value":" 1633/1633 [00:00&lt;00:00, 1842.14it/s]"}},"4f56eb4b6c114ef7935fa093b340badf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9e2735dba8b4414aff430f9b381107d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2185ca3833ed46f8a3ac42b62ab4323f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"94e96a483c814bfdb477f49a56055258":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fed0c514f00d4ba5b3349c8490b0ecfc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aca4b7ec89bc44938003279addba3092":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b449adab27c4ffda3f4262c06fc38aa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1a1194379aa24c9aa1955a2689620626":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_850642955223409a8b0209aa057eb557","IPY_MODEL_25f95b1a76ff4a23a3695e1fde7b148c","IPY_MODEL_20cd04e7d4e04491b442313580d17a4d"],"layout":"IPY_MODEL_0630344613f14b4b9f2306dd734f04e1"}},"850642955223409a8b0209aa057eb557":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_474b9116989a426092fe358f9d3fd384","placeholder":"​","style":"IPY_MODEL_fcb693e34ae048bab9d64bb18438e0f8","value":"100%"}},"25f95b1a76ff4a23a3695e1fde7b148c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d929d78349a4ae797002dc8d20bf62a","max":1633,"min":0,"orientation":"horizontal","style":"IPY_MODEL_149944e9cdcd4314a38889354c4783d4","value":1633}},"20cd04e7d4e04491b442313580d17a4d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f286ff731f7432db4d72d3e18eb12d2","placeholder":"​","style":"IPY_MODEL_8a78e0c76bf64e0b9e02ec906dd21a1b","value":" 1633/1633 [00:01&lt;00:00, 1655.35it/s]"}},"0630344613f14b4b9f2306dd734f04e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"474b9116989a426092fe358f9d3fd384":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fcb693e34ae048bab9d64bb18438e0f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8d929d78349a4ae797002dc8d20bf62a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"149944e9cdcd4314a38889354c4783d4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2f286ff731f7432db4d72d3e18eb12d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a78e0c76bf64e0b9e02ec906dd21a1b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"29e0b33a141e44ecb29c1800813bb239":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4ac0a316855241dfa73c6bbc1067d63b","IPY_MODEL_b4d0d2ea2fb146b1a195c45a32570546","IPY_MODEL_6ec58a15de2e49a88fa076253a4f8f7b"],"layout":"IPY_MODEL_536bd64ff80a408884c2ea8d7ec83f10"}},"4ac0a316855241dfa73c6bbc1067d63b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5a92ab339594d728fe929f5e3b7461e","placeholder":"​","style":"IPY_MODEL_6a209c9c74a74083aad28c9d0fbf593e","value":"100%"}},"b4d0d2ea2fb146b1a195c45a32570546":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_83921d8d93114153a33e0c0050a536d9","max":409,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ae61b2819e644e1d89a9eee93e8349bd","value":409}},"6ec58a15de2e49a88fa076253a4f8f7b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_364404679d7f44efad03e9d61afa24d5","placeholder":"​","style":"IPY_MODEL_c9799a5ace38491fb50d165e2da0dd86","value":" 409/409 [00:00&lt;00:00, 1428.76it/s]"}},"536bd64ff80a408884c2ea8d7ec83f10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5a92ab339594d728fe929f5e3b7461e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a209c9c74a74083aad28c9d0fbf593e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"83921d8d93114153a33e0c0050a536d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae61b2819e644e1d89a9eee93e8349bd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"364404679d7f44efad03e9d61afa24d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9799a5ace38491fb50d165e2da0dd86":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4abe48f41ba14c09b4f8fceb02d83ddc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7b0b2d562f5744669450b13e7437b45e","IPY_MODEL_1bc8af7653514c308fc425b80d860bf8","IPY_MODEL_0c7bae15101e42dbaab1fbc25450b44e"],"layout":"IPY_MODEL_430dc00b9b8448f6b9a4a5b44df91c6b"}},"7b0b2d562f5744669450b13e7437b45e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7fa3d65924264890b1cacc9fc370a23f","placeholder":"​","style":"IPY_MODEL_1cfbf27d2bb04fa98da437baa34f26d7","value":"100%"}},"1bc8af7653514c308fc425b80d860bf8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cab8e27c7d634f5c8ca2ed868b4af795","max":1205,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7e21174e8a0344959d77e23575604a14","value":1205}},"0c7bae15101e42dbaab1fbc25450b44e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce30bae4ba724f84bfcae94099ef75cf","placeholder":"​","style":"IPY_MODEL_086dc1b380cc4a8ca14db6a8635211f8","value":" 1205/1205 [00:00&lt;00:00, 1880.12it/s]"}},"430dc00b9b8448f6b9a4a5b44df91c6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7fa3d65924264890b1cacc9fc370a23f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1cfbf27d2bb04fa98da437baa34f26d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cab8e27c7d634f5c8ca2ed868b4af795":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e21174e8a0344959d77e23575604a14":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ce30bae4ba724f84bfcae94099ef75cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"086dc1b380cc4a8ca14db6a8635211f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a8089b36ab2a4e5aa16eb1785cf88bc9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f97f5a67f69c478fab64bd379e8a2909","IPY_MODEL_1a46b7aab497420bae9f68675487062e","IPY_MODEL_2d88eea003184c06a3764f42ed35ff7a"],"layout":"IPY_MODEL_f36972a695324767a423277ba28663e9"}},"f97f5a67f69c478fab64bd379e8a2909":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b2c6b0fa29794a86968d71e2b15bc5be","placeholder":"​","style":"IPY_MODEL_993fde70956345e2a96077cd266d5062","value":"100%"}},"1a46b7aab497420bae9f68675487062e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9464cd4c4b4421daf7885338d2dd749","max":1205,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2effea6bc59644e58c6630b74cdfd9e9","value":1205}},"2d88eea003184c06a3764f42ed35ff7a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d51e11a3f014aeaae77027b42a25dc2","placeholder":"​","style":"IPY_MODEL_e2e2644e5e35474b971a7eb2c744040b","value":" 1205/1205 [00:00&lt;00:00, 2141.72it/s]"}},"f36972a695324767a423277ba28663e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2c6b0fa29794a86968d71e2b15bc5be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"993fde70956345e2a96077cd266d5062":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e9464cd4c4b4421daf7885338d2dd749":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2effea6bc59644e58c6630b74cdfd9e9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3d51e11a3f014aeaae77027b42a25dc2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2e2644e5e35474b971a7eb2c744040b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e71ade5585c64cbb88f0bfd107397c3b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1a354676211f40bf97e00b8ecaba0bde","IPY_MODEL_ed7a43161ac84e469ebd50e244234e31","IPY_MODEL_440555792aa24b148841deebb9711052"],"layout":"IPY_MODEL_abe4f10b68934f13bf93b860ec339cbc"}},"1a354676211f40bf97e00b8ecaba0bde":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f49e119d9be24ee1ae794b3867562153","placeholder":"​","style":"IPY_MODEL_c203456115d343989bb4026119c2d81a","value":"100%"}},"ed7a43161ac84e469ebd50e244234e31":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0e5b6600d4e4507b454a169b2c74bac","max":38,"min":0,"orientation":"horizontal","style":"IPY_MODEL_be8bd107b54544969544dcf547b2f0f3","value":38}},"440555792aa24b148841deebb9711052":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf91a4f7e550454592483dbf92c4c40c","placeholder":"​","style":"IPY_MODEL_8bf2c34ae5e049f696f89e3fb271f7d4","value":" 38/38 [00:08&lt;00:00,  4.81it/s]"}},"abe4f10b68934f13bf93b860ec339cbc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f49e119d9be24ee1ae794b3867562153":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c203456115d343989bb4026119c2d81a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f0e5b6600d4e4507b454a169b2c74bac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be8bd107b54544969544dcf547b2f0f3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bf91a4f7e550454592483dbf92c4c40c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8bf2c34ae5e049f696f89e3fb271f7d4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import glob\n","import numpy as np\n","from tqdm.notebook import tqdm"],"metadata":{"id":"NR-0k879PtLT","executionInfo":{"status":"ok","timestamp":1669691047387,"user_tz":420,"elapsed":1375,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["Load Data"],"metadata":{"id":"w876m5l2PhGM"}},{"cell_type":"code","source":["df = pd.read_csv('/content/drive/MyDrive/576_project/data/sakthi_full_data/augmented_data/aug_gpt3_data.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/576_project/data/sakthi_full_data/augmented_data/aug_test_data.csv')"],"metadata":{"id":"FZV4ji6wPjX8","executionInfo":{"status":"ok","timestamp":1669691048437,"user_tz":420,"elapsed":898,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"mI8Zt-u8Pv7m","executionInfo":{"status":"ok","timestamp":1669691048438,"user_tz":420,"elapsed":7,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}},"outputId":"3c5205ea-b12d-454e-88fc-24414ec3cf9c"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      Unnamed: 0  index           logic_type            logic_subtype  \\\n","0              0      0    First Order Logic  Universal Instantiation   \n","1              1      1    First Order Logic  Universal Instantiation   \n","2              2      2    First Order Logic  Universal Instantiation   \n","3              3      3    First Order Logic  Universal Instantiation   \n","4              4      4    First Order Logic  Universal Instantiation   \n","...          ...    ...                  ...                      ...   \n","2037        2037   2182  Propositional Logic             Modus Ponens   \n","2038        2038   2183  Propositional Logic             Modus Ponens   \n","2039        2039   2184  Propositional Logic             Modus Ponens   \n","2040        2040   2185  Propositional Logic             Modus Ponens   \n","2041        2041   2186  Propositional Logic             Modus Ponens   \n","\n","     logic_type_code                                            Premise  \\\n","0                 F2  All elephants are mammals.. Curtis is an eleph...   \n","1                 F2              All cats are animals.. Luna is a cat.   \n","2                 F2            All dogs are animals.. Baxter is a dog.   \n","3                 F2              All rats are animals.. Remy is a rat.   \n","4                 F2          All birds are animals.. Tweety is a bird.   \n","...              ...                                                ...   \n","2037              P1              If I am at the beach, I will go swim.   \n","2038              P1  If I have a headache, I will take a pain relie...   \n","2039              P1             If I am tired, I will go to bed early.   \n","2040              P1        If it is raining, I will carry an umbrella.   \n","2041              P1               If I am thirsty, I will drink water.   \n","\n","                        Hypothesis  Labels  \\\n","0              Curtis is a mammal.       1   \n","1               Luna is an animal.       1   \n","2             Baxter is an animal.       1   \n","3               Remy is an animal.       1   \n","4             Tweety is an animal.       1   \n","...                            ...     ...   \n","2037           I will not go swim.       2   \n","2038  I will take a pain reliever.       2   \n","2039       I will go to bed early.       2   \n","2040     I will carry an umbrella.       2   \n","2041           I will drink water.       2   \n","\n","                                     aug_ip_transformer  \n","0     All elephants are mammals Curtis is a mammal. ...  \n","1     All cats are animals Luna is an animal. Luna i...  \n","2     All dogs are animals Baxter is an animal. Baxt...  \n","3     All rats are animals Remy is an animal. Remy i...  \n","4     All birds are animals Tweety is an animal. Twe...  \n","...                                                 ...  \n","2037  If I am at the beach, I will go swim. I will n...  \n","2038  If I have a headache, I will take a pain relie...  \n","2039  If I am tired, I will go to bed early. I will ...  \n","2040  If it is raining, I will carry an umbrella. I ...  \n","2041  If I am thirsty, I will drink water. I will dr...  \n","\n","[2042 rows x 9 columns]"],"text/html":["\n","  <div id=\"df-c0862e75-3e69-4222-b8d9-75e54534c9c6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>index</th>\n","      <th>logic_type</th>\n","      <th>logic_subtype</th>\n","      <th>logic_type_code</th>\n","      <th>Premise</th>\n","      <th>Hypothesis</th>\n","      <th>Labels</th>\n","      <th>aug_ip_transformer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>First Order Logic</td>\n","      <td>Universal Instantiation</td>\n","      <td>F2</td>\n","      <td>All elephants are mammals.. Curtis is an eleph...</td>\n","      <td>Curtis is a mammal.</td>\n","      <td>1</td>\n","      <td>All elephants are mammals Curtis is a mammal. ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>First Order Logic</td>\n","      <td>Universal Instantiation</td>\n","      <td>F2</td>\n","      <td>All cats are animals.. Luna is a cat.</td>\n","      <td>Luna is an animal.</td>\n","      <td>1</td>\n","      <td>All cats are animals Luna is an animal. Luna i...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>First Order Logic</td>\n","      <td>Universal Instantiation</td>\n","      <td>F2</td>\n","      <td>All dogs are animals.. Baxter is a dog.</td>\n","      <td>Baxter is an animal.</td>\n","      <td>1</td>\n","      <td>All dogs are animals Baxter is an animal. Baxt...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>First Order Logic</td>\n","      <td>Universal Instantiation</td>\n","      <td>F2</td>\n","      <td>All rats are animals.. Remy is a rat.</td>\n","      <td>Remy is an animal.</td>\n","      <td>1</td>\n","      <td>All rats are animals Remy is an animal. Remy i...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>First Order Logic</td>\n","      <td>Universal Instantiation</td>\n","      <td>F2</td>\n","      <td>All birds are animals.. Tweety is a bird.</td>\n","      <td>Tweety is an animal.</td>\n","      <td>1</td>\n","      <td>All birds are animals Tweety is an animal. Twe...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2037</th>\n","      <td>2037</td>\n","      <td>2182</td>\n","      <td>Propositional Logic</td>\n","      <td>Modus Ponens</td>\n","      <td>P1</td>\n","      <td>If I am at the beach, I will go swim.</td>\n","      <td>I will not go swim.</td>\n","      <td>2</td>\n","      <td>If I am at the beach, I will go swim. I will n...</td>\n","    </tr>\n","    <tr>\n","      <th>2038</th>\n","      <td>2038</td>\n","      <td>2183</td>\n","      <td>Propositional Logic</td>\n","      <td>Modus Ponens</td>\n","      <td>P1</td>\n","      <td>If I have a headache, I will take a pain relie...</td>\n","      <td>I will take a pain reliever.</td>\n","      <td>2</td>\n","      <td>If I have a headache, I will take a pain relie...</td>\n","    </tr>\n","    <tr>\n","      <th>2039</th>\n","      <td>2039</td>\n","      <td>2184</td>\n","      <td>Propositional Logic</td>\n","      <td>Modus Ponens</td>\n","      <td>P1</td>\n","      <td>If I am tired, I will go to bed early.</td>\n","      <td>I will go to bed early.</td>\n","      <td>2</td>\n","      <td>If I am tired, I will go to bed early. I will ...</td>\n","    </tr>\n","    <tr>\n","      <th>2040</th>\n","      <td>2040</td>\n","      <td>2185</td>\n","      <td>Propositional Logic</td>\n","      <td>Modus Ponens</td>\n","      <td>P1</td>\n","      <td>If it is raining, I will carry an umbrella.</td>\n","      <td>I will carry an umbrella.</td>\n","      <td>2</td>\n","      <td>If it is raining, I will carry an umbrella. I ...</td>\n","    </tr>\n","    <tr>\n","      <th>2041</th>\n","      <td>2041</td>\n","      <td>2186</td>\n","      <td>Propositional Logic</td>\n","      <td>Modus Ponens</td>\n","      <td>P1</td>\n","      <td>If I am thirsty, I will drink water.</td>\n","      <td>I will drink water.</td>\n","      <td>2</td>\n","      <td>If I am thirsty, I will drink water. I will dr...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2042 rows × 9 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0862e75-3e69-4222-b8d9-75e54534c9c6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c0862e75-3e69-4222-b8d9-75e54534c9c6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c0862e75-3e69-4222-b8d9-75e54534c9c6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Fcoks_jQkTu","executionInfo":{"status":"ok","timestamp":1669691057663,"user_tz":420,"elapsed":9229,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}},"outputId":"e9b05003-c4b6-4870-8900-4b52861add17"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n","\u001b[K     |████████████████████████████████| 5.5 MB 4.9 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Collecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 86.6 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.24.0\n"]}]},{"cell_type":"code","source":["import time, datetime"],"metadata":{"id":"pJpVp28LQoxq","executionInfo":{"status":"ok","timestamp":1669691057663,"user_tz":420,"elapsed":6,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["from transformers import RobertaModel, RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig, get_linear_schedule_with_warmup, AdamW"],"metadata":{"id":"6mfcjNziQqrf","executionInfo":{"status":"ok","timestamp":1669691062100,"user_tz":420,"elapsed":4441,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["_config = RobertaConfig.from_pretrained(\"roberta-base\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["85eabe26c8a04200b1a1490d3a85a4c5","63315f617d724721a71b13abe178badd","5ee375653f4745f9b7855758e8c3d544","4611b98519584683a24eab097b354343","7bb0c2c9e2b540c28c464f6347595c66","7cae70d160514a6fa1d03dea280337d7","2eabc637d54c4c95af066c8e581411fa","3c2b250bd46a4e5fbffc8e380ebc78e6","0c0bb26893dc4f5aa73fa9ae517f5d47","3cde9ff3dd20475bb029798815bccc10","15873553bea548e088e92eed939fa918"]},"id":"x5lX_Sm9Qs5r","executionInfo":{"status":"ok","timestamp":1669691063042,"user_tz":420,"elapsed":947,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}},"outputId":"8d219ecc-3ace-4968-cb2f-515fec038cba"},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85eabe26c8a04200b1a1490d3a85a4c5"}},"metadata":{}}]},{"cell_type":"code","source":["_config"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CqnjaqlbQx0y","executionInfo":{"status":"ok","timestamp":1669691063042,"user_tz":420,"elapsed":10,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}},"outputId":"bd6b7c01-3591-4398-950b-ca62cdce221f"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["config = RobertaConfig.from_pretrained(\"roberta-base\", num_hidden_layers= 24, num_attention_heads=24, num_labels=3) # hidden_size=768 must be a multiple of num_attention_heads\n","model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", \n","                                                         config=config, \n","                                                         ignore_mismatched_sizes=True\n","                                                         )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":158,"referenced_widgets":["fb28d90811c6455a9e31d5e4b22ec3cc","d9efc378bf6c4e60af8d7aa4eda79dcf","4e2fc6030ecc4321afe1a3fcbbc82c14","a6087d4725d241688d7086e25956db22","21c76e5632f54ea3b560f1e9ddacd6ab","c9a6ae3fa4b641b6bdce366b805bb8bf","6e4c786adb55432bb8e5a000945e62cc","797b5aa770624c0b8b04b483debbc979","55ec46fe30884fed9cb96a280958b0ef","7807582640864582ba06ce253cafe080","7d092d75a6714bedab5d0dd2cdb5bc8d"]},"id":"yVAvif79Q0HZ","executionInfo":{"status":"ok","timestamp":1669691082282,"user_tz":420,"elapsed":19246,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}},"outputId":"7b195736-dfd0-43b7-dfbf-52394df448d6"},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/501M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb28d90811c6455a9e31d5e4b22ec3cc"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.encoder.layer.23.output.LayerNorm.weight', 'roberta.encoder.layer.15.attention.self.key.weight', 'roberta.encoder.layer.23.output.dense.bias', 'roberta.encoder.layer.22.attention.output.dense.bias', 'roberta.encoder.layer.18.attention.output.dense.weight', 'roberta.encoder.layer.19.intermediate.dense.weight', 'roberta.encoder.layer.12.output.dense.bias', 'roberta.encoder.layer.15.attention.self.value.weight', 'roberta.encoder.layer.12.output.dense.weight', 'roberta.encoder.layer.19.attention.output.dense.bias', 'roberta.encoder.layer.14.output.dense.weight', 'roberta.encoder.layer.23.attention.output.dense.weight', 'roberta.encoder.layer.15.output.LayerNorm.bias', 'roberta.encoder.layer.16.output.LayerNorm.bias', 'roberta.encoder.layer.20.attention.self.value.weight', 'roberta.encoder.layer.14.intermediate.dense.bias', 'roberta.encoder.layer.23.attention.self.value.bias', 'roberta.encoder.layer.23.attention.output.LayerNorm.bias', 'roberta.encoder.layer.13.output.LayerNorm.weight', 'roberta.encoder.layer.20.attention.output.LayerNorm.weight', 'roberta.encoder.layer.12.output.LayerNorm.weight', 'roberta.encoder.layer.21.attention.self.query.weight', 'roberta.encoder.layer.14.attention.output.LayerNorm.bias', 'roberta.encoder.layer.18.output.LayerNorm.weight', 'roberta.encoder.layer.14.attention.self.query.weight', 'roberta.encoder.layer.20.intermediate.dense.weight', 'roberta.encoder.layer.13.attention.output.LayerNorm.weight', 'roberta.encoder.layer.21.intermediate.dense.weight', 'roberta.encoder.layer.20.attention.self.key.weight', 'roberta.encoder.layer.12.attention.self.value.weight', 'roberta.encoder.layer.14.attention.output.dense.bias', 'roberta.encoder.layer.18.output.dense.bias', 'roberta.encoder.layer.12.attention.self.query.bias', 'roberta.encoder.layer.19.attention.output.LayerNorm.bias', 'roberta.encoder.layer.22.attention.self.value.weight', 'roberta.encoder.layer.17.attention.self.key.weight', 'roberta.encoder.layer.15.attention.output.dense.bias', 'roberta.encoder.layer.17.attention.self.value.bias', 'roberta.encoder.layer.15.output.dense.weight', 'roberta.encoder.layer.16.attention.output.dense.bias', 'roberta.encoder.layer.22.output.LayerNorm.weight', 'roberta.encoder.layer.23.intermediate.dense.weight', 'roberta.encoder.layer.23.output.dense.weight', 'roberta.encoder.layer.12.intermediate.dense.bias', 'roberta.encoder.layer.22.intermediate.dense.weight', 'roberta.encoder.layer.16.attention.output.LayerNorm.weight', 'roberta.encoder.layer.23.attention.self.query.bias', 'roberta.encoder.layer.20.intermediate.dense.bias', 'roberta.encoder.layer.13.output.dense.weight', 'roberta.encoder.layer.13.attention.self.key.weight', 'classifier.out_proj.weight', 'roberta.encoder.layer.17.output.dense.bias', 'roberta.encoder.layer.13.attention.self.value.weight', 'roberta.encoder.layer.14.output.LayerNorm.weight', 'roberta.encoder.layer.19.attention.self.query.bias', 'roberta.encoder.layer.13.intermediate.dense.bias', 'roberta.encoder.layer.22.output.dense.bias', 'roberta.encoder.layer.17.output.LayerNorm.weight', 'roberta.encoder.layer.22.output.LayerNorm.bias', 'roberta.encoder.layer.18.attention.self.query.weight', 'classifier.dense.bias', 'roberta.encoder.layer.13.output.dense.bias', 'roberta.encoder.layer.22.attention.self.query.weight', 'classifier.out_proj.bias', 'roberta.encoder.layer.22.attention.output.dense.weight', 'roberta.encoder.layer.14.intermediate.dense.weight', 'roberta.encoder.layer.15.attention.output.dense.weight', 'roberta.encoder.layer.19.attention.self.value.weight', 'roberta.encoder.layer.20.attention.output.LayerNorm.bias', 'roberta.encoder.layer.12.attention.self.value.bias', 'roberta.encoder.layer.21.output.dense.bias', 'roberta.encoder.layer.23.attention.self.key.bias', 'roberta.encoder.layer.18.output.dense.weight', 'roberta.encoder.layer.23.intermediate.dense.bias', 'roberta.encoder.layer.13.intermediate.dense.weight', 'roberta.encoder.layer.15.output.dense.bias', 'roberta.encoder.layer.14.attention.self.query.bias', 'roberta.encoder.layer.16.output.LayerNorm.weight', 'roberta.encoder.layer.13.attention.output.dense.bias', 'roberta.encoder.layer.19.output.LayerNorm.weight', 'roberta.encoder.layer.21.output.LayerNorm.weight', 'roberta.encoder.layer.17.attention.self.query.weight', 'roberta.encoder.layer.13.attention.self.value.bias', 'roberta.encoder.layer.17.intermediate.dense.bias', 'roberta.encoder.layer.20.attention.output.dense.bias', 'roberta.encoder.layer.15.intermediate.dense.weight', 'roberta.encoder.layer.16.output.dense.bias', 'roberta.encoder.layer.20.output.dense.weight', 'roberta.encoder.layer.13.attention.self.key.bias', 'roberta.encoder.layer.19.intermediate.dense.bias', 'roberta.encoder.layer.18.attention.output.dense.bias', 'roberta.encoder.layer.16.attention.output.LayerNorm.bias', 'roberta.encoder.layer.18.output.LayerNorm.bias', 'roberta.encoder.layer.20.output.dense.bias', 'roberta.encoder.layer.18.intermediate.dense.weight', 'roberta.encoder.layer.22.attention.output.LayerNorm.bias', 'roberta.encoder.layer.18.attention.self.query.bias', 'roberta.encoder.layer.20.attention.self.key.bias', 'roberta.encoder.layer.12.attention.output.LayerNorm.weight', 'roberta.encoder.layer.12.attention.self.key.bias', 'roberta.encoder.layer.17.output.dense.weight', 'roberta.encoder.layer.17.attention.output.dense.weight', 'roberta.encoder.layer.14.attention.self.value.weight', 'roberta.encoder.layer.19.output.LayerNorm.bias', 'roberta.encoder.layer.13.attention.output.dense.weight', 'roberta.encoder.layer.14.attention.output.LayerNorm.weight', 'roberta.encoder.layer.12.output.LayerNorm.bias', 'roberta.encoder.layer.13.attention.self.query.bias', 'roberta.encoder.layer.21.attention.output.LayerNorm.bias', 'roberta.encoder.layer.18.attention.output.LayerNorm.weight', 'roberta.encoder.layer.20.output.LayerNorm.bias', 'roberta.encoder.layer.13.attention.self.query.weight', 'roberta.encoder.layer.23.attention.self.query.weight', 'roberta.encoder.layer.16.attention.self.key.weight', 'roberta.encoder.layer.16.output.dense.weight', 'roberta.encoder.layer.12.attention.output.dense.weight', 'roberta.encoder.layer.19.attention.output.dense.weight', 'roberta.encoder.layer.19.output.dense.weight', 'roberta.encoder.layer.14.attention.self.key.weight', 'roberta.encoder.layer.17.attention.self.query.bias', 'roberta.encoder.layer.12.attention.output.LayerNorm.bias', 'roberta.encoder.layer.19.attention.self.key.weight', 'roberta.encoder.layer.12.attention.self.key.weight', 'roberta.encoder.layer.21.attention.self.key.bias', 'roberta.encoder.layer.22.intermediate.dense.bias', 'roberta.encoder.layer.22.attention.self.query.bias', 'roberta.encoder.layer.16.attention.self.query.weight', 'roberta.encoder.layer.15.output.LayerNorm.weight', 'roberta.encoder.layer.22.attention.self.key.bias', 'roberta.encoder.layer.22.attention.self.key.weight', 'roberta.encoder.layer.23.output.LayerNorm.bias', 'roberta.encoder.layer.21.attention.output.dense.bias', 'roberta.encoder.layer.14.attention.self.value.bias', 'roberta.encoder.layer.15.attention.self.query.bias', 'roberta.encoder.layer.15.attention.output.LayerNorm.bias', 'roberta.encoder.layer.20.attention.self.query.weight', 'roberta.encoder.layer.21.attention.self.value.bias', 'roberta.encoder.layer.12.intermediate.dense.weight', 'roberta.encoder.layer.14.output.dense.bias', 'roberta.encoder.layer.16.attention.self.value.weight', 'roberta.encoder.layer.20.output.LayerNorm.weight', 'roberta.encoder.layer.12.attention.output.dense.bias', 'roberta.encoder.layer.21.output.LayerNorm.bias', 'roberta.encoder.layer.14.attention.self.key.bias', 'roberta.encoder.layer.17.attention.output.LayerNorm.bias', 'roberta.encoder.layer.15.attention.self.value.bias', 'roberta.encoder.layer.19.attention.output.LayerNorm.weight', 'roberta.encoder.layer.18.attention.self.value.bias', 'roberta.encoder.layer.14.output.LayerNorm.bias', 'roberta.encoder.layer.19.output.dense.bias', 'roberta.encoder.layer.18.attention.output.LayerNorm.bias', 'roberta.encoder.layer.21.intermediate.dense.bias', 'roberta.encoder.layer.16.intermediate.dense.bias', 'roberta.encoder.layer.16.attention.output.dense.weight', 'roberta.encoder.layer.21.attention.self.query.bias', 'roberta.encoder.layer.13.attention.output.LayerNorm.bias', 'roberta.encoder.layer.21.attention.self.key.weight', 'roberta.encoder.layer.20.attention.output.dense.weight', 'roberta.encoder.layer.15.attention.output.LayerNorm.weight', 'roberta.encoder.layer.17.output.LayerNorm.bias', 'roberta.encoder.layer.23.attention.self.value.weight', 'roberta.encoder.layer.18.attention.self.value.weight', 'roberta.encoder.layer.19.attention.self.value.bias', 'roberta.encoder.layer.23.attention.output.LayerNorm.weight', 'roberta.encoder.layer.18.intermediate.dense.bias', 'roberta.encoder.layer.15.attention.self.key.bias', 'roberta.encoder.layer.16.attention.self.query.bias', 'roberta.encoder.layer.17.attention.output.dense.bias', 'roberta.encoder.layer.21.attention.output.LayerNorm.weight', 'roberta.encoder.layer.15.intermediate.dense.bias', 'roberta.encoder.layer.13.output.LayerNorm.bias', 'roberta.encoder.layer.22.output.dense.weight', 'roberta.encoder.layer.16.intermediate.dense.weight', 'roberta.encoder.layer.22.attention.self.value.bias', 'roberta.encoder.layer.14.attention.output.dense.weight', 'roberta.encoder.layer.16.attention.self.value.bias', 'roberta.encoder.layer.17.intermediate.dense.weight', 'roberta.encoder.layer.23.attention.self.key.weight', 'classifier.dense.weight', 'roberta.encoder.layer.17.attention.output.LayerNorm.weight', 'roberta.encoder.layer.21.attention.self.value.weight', 'roberta.encoder.layer.16.attention.self.key.bias', 'roberta.encoder.layer.19.attention.self.query.weight', 'roberta.encoder.layer.22.attention.output.LayerNorm.weight', 'roberta.encoder.layer.15.attention.self.query.weight', 'roberta.encoder.layer.21.attention.output.dense.weight', 'roberta.encoder.layer.17.attention.self.key.bias', 'roberta.encoder.layer.18.attention.self.key.bias', 'roberta.encoder.layer.19.attention.self.key.bias', 'roberta.encoder.layer.20.attention.self.value.bias', 'roberta.encoder.layer.12.attention.self.query.weight', 'roberta.encoder.layer.17.attention.self.value.weight', 'roberta.encoder.layer.18.attention.self.key.weight', 'roberta.encoder.layer.23.attention.output.dense.bias', 'roberta.encoder.layer.20.attention.self.query.bias', 'roberta.encoder.layer.21.output.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["model.config\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CQgeL6rKRSy9","executionInfo":{"status":"ok","timestamp":1669691082283,"user_tz":420,"elapsed":31,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}},"outputId":"b9f52929-71e1-4a61-a934-28d2040878cb"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RobertaConfig {\n","  \"_name_or_path\": \"roberta-base\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 24,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["model\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yD20_2AcRm6v","executionInfo":{"status":"ok","timestamp":1669691082283,"user_tz":420,"elapsed":25,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}},"outputId":"59050e38-c0f3-4667-a89c-bfa650345d28"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RobertaForSequenceClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (12): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (13): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (14): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (15): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (16): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (17): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (18): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (19): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (20): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (21): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (22): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (23): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): RobertaClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["roberta_tok = RobertaTokenizer.from_pretrained(\"roberta-base\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["57e7fc0f5e9649eca4c332c15c25ee39","b51ef49ce7b5419e94db80bbd7b511c2","3561ced4fd3e4c6e964d51abb1fe0695","1ad5fb59f5e945e79b45752d3cb5e448","bade978927c8499ca106472424c10beb","2f0416985b234890926ba2005cdb9972","cf074472dfd54bcc8f448f372aff9386","5dedaa76b60b4ee3bcf3ee8992e81306","4a9376a372784470810f668fc9fa1907","b8a9eb5e08d041c1923b52fe5ab3bd37","b7e6f0b986dd47c4a7afaf2ef5fdc96a","b683ed57da4744f8974b2f4be5c9e9b5","aa8b021449874258b260f204839c39bc","f113b15bf64a48fca5dbb2c16b0e16fa","4b50b0229e364c4793ea4651844b2b2c","63cf8c5168ee46d98fb63fadc32c8cb6","4ea4bc8bc4e94063941348dc9e999bfe","0e8c166a22b74060867ee1baa450a0ce","8f4f6030979b48b89ba28a426d799457","dd2304f34218404b90e0236a5311b7cc","edeb354a9c3940bd9d9fba551e521f83","5a69212f561c4506b770eb18b94ac220"]},"id":"t1POd2BdRtJK","executionInfo":{"status":"ok","timestamp":1669691083724,"user_tz":420,"elapsed":1460,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}},"outputId":"e4227c38-91e5-4c57-ab05-ec6b732af262"},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57e7fc0f5e9649eca4c332c15c25ee39"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b683ed57da4744f8974b2f4be5c9e9b5"}},"metadata":{}}]},{"cell_type":"code","source":["import torch\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"XZqo_X_iRvYo","executionInfo":{"status":"ok","timestamp":1669691084367,"user_tz":420,"elapsed":644,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["X_train, X_val, y_train, y_val = train_test_split(\n","    df.drop(columns=[\"logic_type\", \"logic_subtype\", \"logic_type_code\", \"Labels\"]),\n","    df[\"Labels\"],\n","    stratify = df[\"Labels\"],\n","    test_size = 0.2\n",")"],"metadata":{"id":"NzKp015HR06z","executionInfo":{"status":"ok","timestamp":1669691084370,"user_tz":420,"elapsed":21,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["y_train.value_counts()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_KDCH_eHR25d","executionInfo":{"status":"ok","timestamp":1669691084371,"user_tz":420,"elapsed":21,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}},"outputId":"1f7c84b4-81d1-4645-91bb-0900706186cb"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    1074\n","0     447\n","2     112\n","Name: Labels, dtype: int64"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["y_val.value_counts()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9FCtBvNCR8jW","executionInfo":{"status":"ok","timestamp":1669691084371,"user_tz":420,"elapsed":14,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}},"outputId":"26d7db08-47b8-48b4-c1c1-45c65301b727"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    269\n","0    112\n","2     28\n","Name: Labels, dtype: int64"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["y_train.value_counts()[0]/y_val.value_counts()[0], y_train.value_counts()[1]/y_val.value_counts()[1], y_train.value_counts()[2]/y_val.value_counts()[2]\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wJ7ev5gmR-zn","executionInfo":{"status":"ok","timestamp":1669691084372,"user_tz":420,"elapsed":13,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}},"outputId":"b2672e11-46a2-4944-a394-07e85b12f6dc"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3.9910714285714284, 3.992565055762082, 4.0)"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["X_train.head(2)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":208},"id":"SJ7VmtNpSFv4","executionInfo":{"status":"ok","timestamp":1669691084373,"user_tz":420,"elapsed":12,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}},"outputId":"34b27fc8-dff4-436a-c8f0-47e1eebbf88f"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      Unnamed: 0  index                                            Premise  \\\n","464          464    504  If the trial goes well, he will be acquitted.....   \n","1779        1779   1924  After an action is performed, things normally ...   \n","\n","                                             Hypothesis  \\\n","464                                   He was acquitted.   \n","1779  The robot grasps an item and then waits, the i...   \n","\n","                                     aug_ip_transformer  \n","464   If the trial goes well, he will be acquitted H...  \n","1779  After an action is performed, things normally ...  "],"text/html":["\n","  <div id=\"df-50d559c8-aae7-4a17-b9fa-3b52a407f751\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>index</th>\n","      <th>Premise</th>\n","      <th>Hypothesis</th>\n","      <th>aug_ip_transformer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>464</th>\n","      <td>464</td>\n","      <td>504</td>\n","      <td>If the trial goes well, he will be acquitted.....</td>\n","      <td>He was acquitted.</td>\n","      <td>If the trial goes well, he will be acquitted H...</td>\n","    </tr>\n","    <tr>\n","      <th>1779</th>\n","      <td>1779</td>\n","      <td>1924</td>\n","      <td>After an action is performed, things normally ...</td>\n","      <td>The robot grasps an item and then waits, the i...</td>\n","      <td>After an action is performed, things normally ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50d559c8-aae7-4a17-b9fa-3b52a407f751')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-50d559c8-aae7-4a17-b9fa-3b52a407f751 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-50d559c8-aae7-4a17-b9fa-3b52a407f751');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["test_df.head(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":367},"id":"9vJIBpoMSH6s","executionInfo":{"status":"ok","timestamp":1669691084373,"user_tz":420,"elapsed":11,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}},"outputId":"6e3155cb-b331-4846-ca08-bae3975c5931"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Unnamed: 0  index              logic_type  \\\n","0           0      0  Reasoning about Action   \n","1           1      1  Reasoning about Action   \n","\n","                           logic_subtype logic_type_code  \\\n","0  Frame Problem for Temporal Projection              D1   \n","1  Frame Problem for Temporal Projection              D1   \n","\n","                                             Premise  \\\n","0  After an action is performed, things normally ...   \n","1  After an action is performed, things normally ...   \n","\n","                                          Hypothesis  Label  Labels  \\\n","0  After the robot grasps the pipe, waits, then m...   True       1   \n","1  After the robot grasps the pipe, waits, then d...  False       0   \n","\n","                                  aug_ip_transformer  \n","0  After an action is performed, things normally ...  \n","1  After an action is performed, things normally ...  "],"text/html":["\n","  <div id=\"df-375438bf-969b-4cee-a6ad-0cbe030679b0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>index</th>\n","      <th>logic_type</th>\n","      <th>logic_subtype</th>\n","      <th>logic_type_code</th>\n","      <th>Premise</th>\n","      <th>Hypothesis</th>\n","      <th>Label</th>\n","      <th>Labels</th>\n","      <th>aug_ip_transformer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Reasoning about Action</td>\n","      <td>Frame Problem for Temporal Projection</td>\n","      <td>D1</td>\n","      <td>After an action is performed, things normally ...</td>\n","      <td>After the robot grasps the pipe, waits, then m...</td>\n","      <td>True</td>\n","      <td>1</td>\n","      <td>After an action is performed, things normally ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Reasoning about Action</td>\n","      <td>Frame Problem for Temporal Projection</td>\n","      <td>D1</td>\n","      <td>After an action is performed, things normally ...</td>\n","      <td>After the robot grasps the pipe, waits, then d...</td>\n","      <td>False</td>\n","      <td>0</td>\n","      <td>After an action is performed, things normally ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-375438bf-969b-4cee-a6ad-0cbe030679b0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-375438bf-969b-4cee-a6ad-0cbe030679b0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-375438bf-969b-4cee-a6ad-0cbe030679b0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["train_aug_ip = X_train[\"aug_ip_transformer\"].values\n","train_labels = y_train.values\n","\n","val_aug_ip = X_val[\"aug_ip_transformer\"].values\n","val_labels = y_val.values\n","\n","test_aug_ip = test_df[\"aug_ip_transformer\"].values\n","test_labels = test_df.Labels.values"],"metadata":{"id":"3ERI15o7SPLC","executionInfo":{"status":"ok","timestamp":1669691084373,"user_tz":420,"elapsed":10,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["max_len=0\n","for i in tqdm(range(0,len(train_aug_ip))):\n","  input_ids = roberta_tok.encode(train_aug_ip[i], add_special_tokens=True)\n","  max_len = max(max_len, len(input_ids))\n","\n","print(f\"Max Length in Train Dataset: {max_len}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["e55401ba967c401daf61c9aa93791e34","50bde6ee74784b5398a8566948387120","2a0fc219ff1b4b3b8ad1b4d321f5020f","a32fa5edd52047f89eab42270923030c","4f56eb4b6c114ef7935fa093b340badf","c9e2735dba8b4414aff430f9b381107d","2185ca3833ed46f8a3ac42b62ab4323f","94e96a483c814bfdb477f49a56055258","fed0c514f00d4ba5b3349c8490b0ecfc","aca4b7ec89bc44938003279addba3092","0b449adab27c4ffda3f4262c06fc38aa"]},"id":"9ADBtWpPSP-V","executionInfo":{"status":"ok","timestamp":1669691085471,"user_tz":420,"elapsed":1108,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}},"outputId":"c7977ee0-1787-4146-a44a-53134ee575bf"},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1633 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e55401ba967c401daf61c9aa93791e34"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Max Length in Train Dataset: 349\n"]}]},{"cell_type":"code","source":["def encode_input(aug_ip_transformer, label, maxlen):\n","\n","  encoded_input_ids = []\n","  encoded_input_attn_mask = []\n","\n","  for i in tqdm(range(0, len(aug_ip_transformer))):\n","    encoded_input = roberta_tok.encode_plus(aug_ip_transformer[i],\n","                                        add_special_tokens=True,\n","                                        max_length=maxlen,\n","                                        return_attention_mask=True,\n","                                        return_tensors=\"pt\",\n","                                        truncation=True,\n","                                        padding=\"max_length\")\n","    \n","    encoded_input_ids.append(encoded_input.input_ids)\n","    encoded_input_attn_mask.append(encoded_input.attention_mask)\n","\n","  encoded_input_ids = torch.cat(encoded_input_ids, dim=0)\n","  encoded_input_attn_mask = torch.cat(encoded_input_attn_mask, dim=0)\n","  label = torch.tensor(label, dtype=torch.long)\n","\n","  return (encoded_input_ids, encoded_input_attn_mask, label)"],"metadata":{"id":"Vd_wwscmSnUm","executionInfo":{"status":"ok","timestamp":1669691085472,"user_tz":420,"elapsed":8,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["train_encoded_input_ids, train_encoded_input_attn_mask, train_label = encode_input(aug_ip_transformer = train_aug_ip, label = train_labels, maxlen = 512)\n","val_encoded_input_ids, val_encoded_input_attn_mask, val_label = encode_input(aug_ip_transformer = val_aug_ip, label = val_labels, maxlen = 512)\n","test_encoded_input_ids, test_encoded_input_attn_mask, test_label = encode_input(aug_ip_transformer = test_aug_ip, label = test_labels, maxlen = 512)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["1a1194379aa24c9aa1955a2689620626","850642955223409a8b0209aa057eb557","25f95b1a76ff4a23a3695e1fde7b148c","20cd04e7d4e04491b442313580d17a4d","0630344613f14b4b9f2306dd734f04e1","474b9116989a426092fe358f9d3fd384","fcb693e34ae048bab9d64bb18438e0f8","8d929d78349a4ae797002dc8d20bf62a","149944e9cdcd4314a38889354c4783d4","2f286ff731f7432db4d72d3e18eb12d2","8a78e0c76bf64e0b9e02ec906dd21a1b","29e0b33a141e44ecb29c1800813bb239","4ac0a316855241dfa73c6bbc1067d63b","b4d0d2ea2fb146b1a195c45a32570546","6ec58a15de2e49a88fa076253a4f8f7b","536bd64ff80a408884c2ea8d7ec83f10","e5a92ab339594d728fe929f5e3b7461e","6a209c9c74a74083aad28c9d0fbf593e","83921d8d93114153a33e0c0050a536d9","ae61b2819e644e1d89a9eee93e8349bd","364404679d7f44efad03e9d61afa24d5","c9799a5ace38491fb50d165e2da0dd86","4abe48f41ba14c09b4f8fceb02d83ddc","7b0b2d562f5744669450b13e7437b45e","1bc8af7653514c308fc425b80d860bf8","0c7bae15101e42dbaab1fbc25450b44e","430dc00b9b8448f6b9a4a5b44df91c6b","7fa3d65924264890b1cacc9fc370a23f","1cfbf27d2bb04fa98da437baa34f26d7","cab8e27c7d634f5c8ca2ed868b4af795","7e21174e8a0344959d77e23575604a14","ce30bae4ba724f84bfcae94099ef75cf","086dc1b380cc4a8ca14db6a8635211f8"]},"id":"jM4aNlKLSxNJ","executionInfo":{"status":"ok","timestamp":1669691087551,"user_tz":420,"elapsed":2086,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}},"outputId":"c07ba4c7-d2d1-42a6-b7af-265bafc165d6"},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1633 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a1194379aa24c9aa1955a2689620626"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/409 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29e0b33a141e44ecb29c1800813bb239"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1205 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4abe48f41ba14c09b4f8fceb02d83ddc"}},"metadata":{}}]},{"cell_type":"code","source":["print(f\"Original Premise 1: {train_aug_ip[0]}\")\n","print(f\"Token IDs: {train_encoded_input_ids[0]}\")\n","print(f\"Attention Mask: {train_encoded_input_attn_mask[0]}\")\n","print(f\"Label: {train_labels[0]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_jVxOKWWS16v","executionInfo":{"status":"ok","timestamp":1669691087551,"user_tz":420,"elapsed":11,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}},"outputId":"d04df023-4844-4f85-c126-f1dd41a45322"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Original Premise 1: If the trial goes well, he will be acquitted He was acquitted. The trial went well.[SEP]He was acquitted.\n","Token IDs: tensor([    0,  1106,     5,  1500,  1411,   157,     6,    37,    40,    28,\n","        17871,    91,    21, 17871,     4,    20,  1500,   439,   157, 31274,\n","         3388,   510,   742,   894,    21, 17871,     4,     2,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","            1,     1])\n","Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0])\n","Label: 1\n"]}]},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"],"metadata":{"id":"S2OEUxu9S558","executionInfo":{"status":"ok","timestamp":1669691087551,"user_tz":420,"elapsed":5,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["train_ds = TensorDataset(train_encoded_input_ids, train_encoded_input_attn_mask, train_label)\n","eval_ds = TensorDataset(val_encoded_input_ids, val_encoded_input_attn_mask, val_label)\n","test_ds= TensorDataset(test_encoded_input_ids, test_encoded_input_attn_mask, test_label)"],"metadata":{"id":"oMfyRxmgTA8O","executionInfo":{"status":"ok","timestamp":1669691087552,"user_tz":420,"elapsed":5,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["config = {\n","    \"eos_token\" : \"[SEP]\",\n","    \"batch_size\" : 8,\n","    \"random_seed\" : 7\n","}"],"metadata":{"id":"bBMEkMyzTFha","executionInfo":{"status":"ok","timestamp":1669691087552,"user_tz":420,"elapsed":5,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["train_dataloader = DataLoader(\n","            train_ds,  \n","            sampler = RandomSampler(train_ds), \n","            batch_size = config[\"batch_size\"]\n","        )\n","\n","validation_dataloader = DataLoader(\n","            eval_ds, \n","            sampler = RandomSampler(eval_ds), \n","            batch_size = config[\"batch_size\"]\n","        )\n","\n","test_dataloader = DataLoader(\n","            test_ds, \n","            sampler = RandomSampler(test_ds), \n","            batch_size = config[\"batch_size\"]\n","        )"],"metadata":{"id":"UWq6JD6GTH3y","executionInfo":{"status":"ok","timestamp":1669691087552,"user_tz":420,"elapsed":5,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["model.to(\"cuda:0\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jiZqgFpiTLoF","executionInfo":{"status":"ok","timestamp":1669691091530,"user_tz":420,"elapsed":3983,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}},"outputId":"eeefc973-8167-49e4-fba6-6e6483da41b3"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RobertaForSequenceClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (12): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (13): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (14): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (15): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (16): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (17): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (18): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (19): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (20): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (21): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (22): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (23): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): RobertaClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["EPOCHS = 7\n","LR = 2e-5\n","EPS = 1e-8\n","\n","optimizer = AdamW(model.parameters(), lr = LR, eps = EPS)\n","total_steps = len(train_dataloader) * EPOCHS\n","\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                           num_warmup_steps = 0, \n","                                           num_training_steps = total_steps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YF0T_I8qTN_3","executionInfo":{"status":"ok","timestamp":1669691091530,"user_tz":420,"elapsed":19,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}},"outputId":"7f587f41-5a5a-43eb-d3ff-509798b4acb7"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]}]},{"cell_type":"code","source":["# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"metadata":{"id":"cCHe-SdyTWnL","executionInfo":{"status":"ok","timestamp":1669691091531,"user_tz":420,"elapsed":6,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"metadata":{"id":"Q623PT__Ti9R","executionInfo":{"status":"ok","timestamp":1669691091531,"user_tz":420,"elapsed":6,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["import random\n","import numpy as np"],"metadata":{"id":"A0WH_VClTjqq","executionInfo":{"status":"ok","timestamp":1669691091531,"user_tz":420,"elapsed":6,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["random.seed(config[\"random_seed\"])\n","np.random.seed(config[\"random_seed\"])\n","torch.manual_seed(config[\"random_seed\"])\n","torch.cuda.manual_seed_all(config[\"random_seed\"])"],"metadata":{"id":"o4wvg_ALTmbb","executionInfo":{"status":"ok","timestamp":1669691091531,"user_tz":420,"elapsed":6,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["for i in train_dataloader:\n","  print(f\"{i[0]} \\n\\n {i[1]} \\n\\n {i[2]}\")\n","  break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0ZReZyQdToE4","executionInfo":{"status":"ok","timestamp":1669691091531,"user_tz":420,"elapsed":6,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}},"outputId":"68b7412a-d4cf-4a4d-8da5-816de2f5049e"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[   0, 4993,   41,  ...,    1,    1,    1],\n","        [   0, 3684, 5868,  ...,    1,    1,    1],\n","        [   0, 1106,   38,  ...,    1,    1,    1],\n","        ...,\n","        [   0, 1106,   38,  ...,    1,    1,    1],\n","        [   0, 3684, 3678,  ...,    1,    1,    1],\n","        [   0, 3684, 2879,  ...,    1,    1,    1]]) \n","\n"," tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]) \n","\n"," tensor([1, 1, 0, 0, 1, 1, 0, 1])\n"]}]},{"cell_type":"code","source":["# CELL EXTRACTED FROM SAMPLE NOTEBOOK PROVIDED\n","\n","training_stats = []\n","epochs = EPOCHS\n","\n","# Measure the total training time for the whole run.\n","total_t0 = time.time()\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_train_loss = 0\n","\n","    # Put the model into training mode. Don't be mislead--the call to \n","    # `train` just changes the *mode*, it doesn't *perform* the training.\n","    # `dropout` and `batchnorm` layers behave differently during training\n","    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n","        # `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(\"cuda:0\")\n","        b_input_mask = batch[1].to(\"cuda:0\")\n","        b_labels = batch[2].to(\"cuda:0\")\n","\n","        # Always clear any previously calculated gradients before performing a\n","        # backward pass. PyTorch doesn't do this automatically because \n","        # accumulating the gradients is \"convenient while training RNNs\". \n","        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n","        model.zero_grad()        \n","\n","        # Perform a forward pass (evaluate the model on this training batch).\n","        # In PyTorch, calling `model` will in turn call the model's `forward` \n","        # function and pass down the arguments. The `forward` function is \n","        # documented here: \n","        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n","        # The results are returned in a results object, documented here:\n","        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n","        # Specifically, we'll get the loss (because we provided labels) and the\n","        # \"logits\"--the model outputs prior to activation.\n","        result = model(b_input_ids, \n","                       token_type_ids=None, \n","                       attention_mask=b_input_mask, \n","                       labels=b_labels,\n","                       return_dict=True)\n","\n","        loss = result.loss\n","        logits = result.logits\n","\n","        # Accumulate the training loss over all of the batches so that we can\n","        # calculate the average loss at the end. `loss` is a Tensor containing a\n","        # single value; the `.item()` function just returns the Python value \n","        # from the tensor.\n","        total_train_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        # The optimizer dictates the \"update rule\"--how the parameters are\n","        # modified based on their gradients, the learning rate, etc.\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_train_loss = total_train_loss / len(train_dataloader)            \n","    \n","    # Measure how long this epoch took.\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(training_time))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    # Put the model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    model.eval()\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        \n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using \n","        # the `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(\"cuda:0\")\n","        b_input_mask = batch[1].to(\"cuda:0\")\n","        b_labels = batch[2].to(\"cuda:0\")\n","        \n","        # Tell pytorch not to bother with constructing the compute graph during\n","        # the forward pass, since this is only needed for backprop (training).\n","        with torch.no_grad():        \n","\n","            # Forward pass, calculate logit predictions.\n","            # token_type_ids is the same as the \"segment ids\", which \n","            # differentiates sentence 1 and 2 in 2-sentence tasks.\n","            result = model(b_input_ids, \n","                           token_type_ids=None, \n","                           attention_mask=b_input_mask,\n","                           labels=b_labels,\n","                           return_dict=True)\n","\n","        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n","        # output values prior to applying an activation function like the \n","        # softmax.\n","        loss = result.loss\n","        logits = result.logits\n","            \n","        # Accumulate the validation loss.\n","        total_eval_loss += loss.item()\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the accuracy for this batch of test sentences, and\n","        # accumulate it over all batches.\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\n","        \n","\n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\n","    \n","    # Measure how long the validation run took.\n","    validation_time = format_time(time.time() - t0)\n","    \n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","\n","    # Record all statistics from this epoch.\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_val_loss,\n","            'Valid. Accur.': avg_val_accuracy,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"042MMWx8TpRu","executionInfo":{"status":"ok","timestamp":1669691832995,"user_tz":420,"elapsed":741468,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}},"outputId":"2149757d-9d2c-4f88-c14c-300b9fd7b3d8"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======== Epoch 1 / 7 ========\n","Training...\n","  Batch    40  of    205.    Elapsed: 0:00:22.\n","  Batch    80  of    205.    Elapsed: 0:00:41.\n","  Batch   120  of    205.    Elapsed: 0:01:00.\n","  Batch   160  of    205.    Elapsed: 0:01:20.\n","  Batch   200  of    205.    Elapsed: 0:01:39.\n","\n","  Average training loss: 0.85\n","  Training epcoh took: 0:01:41\n","\n","Running Validation...\n","  Accuracy: 0.58\n","  Validation Loss: 0.77\n","  Validation took: 0:00:07\n","\n","======== Epoch 2 / 7 ========\n","Training...\n","  Batch    40  of    205.    Elapsed: 0:00:19.\n","  Batch    80  of    205.    Elapsed: 0:00:39.\n","  Batch   120  of    205.    Elapsed: 0:00:58.\n","  Batch   160  of    205.    Elapsed: 0:01:17.\n","  Batch   200  of    205.    Elapsed: 0:01:36.\n","\n","  Average training loss: 0.75\n","  Training epcoh took: 0:01:38\n","\n","Running Validation...\n","  Accuracy: 0.68\n","  Validation Loss: 0.75\n","  Validation took: 0:00:07\n","\n","======== Epoch 3 / 7 ========\n","Training...\n","  Batch    40  of    205.    Elapsed: 0:00:19.\n","  Batch    80  of    205.    Elapsed: 0:00:39.\n","  Batch   120  of    205.    Elapsed: 0:00:58.\n","  Batch   160  of    205.    Elapsed: 0:01:17.\n","  Batch   200  of    205.    Elapsed: 0:01:36.\n","\n","  Average training loss: 0.65\n","  Training epcoh took: 0:01:38\n","\n","Running Validation...\n","  Accuracy: 0.72\n","  Validation Loss: 0.71\n","  Validation took: 0:00:07\n","\n","======== Epoch 4 / 7 ========\n","Training...\n","  Batch    40  of    205.    Elapsed: 0:00:19.\n","  Batch    80  of    205.    Elapsed: 0:00:39.\n","  Batch   120  of    205.    Elapsed: 0:00:58.\n","  Batch   160  of    205.    Elapsed: 0:01:17.\n","  Batch   200  of    205.    Elapsed: 0:01:36.\n","\n","  Average training loss: 0.55\n","  Training epcoh took: 0:01:38\n","\n","Running Validation...\n","  Accuracy: 0.73\n","  Validation Loss: 0.82\n","  Validation took: 0:00:07\n","\n","======== Epoch 5 / 7 ========\n","Training...\n","  Batch    40  of    205.    Elapsed: 0:00:19.\n","  Batch    80  of    205.    Elapsed: 0:00:39.\n","  Batch   120  of    205.    Elapsed: 0:00:58.\n","  Batch   160  of    205.    Elapsed: 0:01:17.\n","  Batch   200  of    205.    Elapsed: 0:01:36.\n","\n","  Average training loss: 0.57\n","  Training epcoh took: 0:01:38\n","\n","Running Validation...\n","  Accuracy: 0.75\n","  Validation Loss: 0.85\n","  Validation took: 0:00:07\n","\n","======== Epoch 6 / 7 ========\n","Training...\n","  Batch    40  of    205.    Elapsed: 0:00:19.\n","  Batch    80  of    205.    Elapsed: 0:00:39.\n","  Batch   120  of    205.    Elapsed: 0:00:58.\n","  Batch   160  of    205.    Elapsed: 0:01:17.\n","  Batch   200  of    205.    Elapsed: 0:01:36.\n","\n","  Average training loss: 0.43\n","  Training epcoh took: 0:01:38\n","\n","Running Validation...\n","  Accuracy: 0.77\n","  Validation Loss: 0.85\n","  Validation took: 0:00:07\n","\n","======== Epoch 7 / 7 ========\n","Training...\n","  Batch    40  of    205.    Elapsed: 0:00:19.\n","  Batch    80  of    205.    Elapsed: 0:00:39.\n","  Batch   120  of    205.    Elapsed: 0:00:58.\n","  Batch   160  of    205.    Elapsed: 0:01:17.\n","  Batch   200  of    205.    Elapsed: 0:01:36.\n","\n","  Average training loss: 0.39\n","  Training epcoh took: 0:01:38\n","\n","Running Validation...\n","  Accuracy: 0.75\n","  Validation Loss: 0.89\n","  Validation took: 0:00:07\n","\n","Training complete!\n","Total training took 0:12:21 (h:mm:ss)\n"]}]},{"cell_type":"code","source":["# CELL EXTRACTED FROM SAMPLE NOTEBOOK PROVIDED\n","\n","# Display floats with two decimal places.\n","pd.set_option('precision', 2)\n","\n","# Create a DataFrame from our training statistics.\n","df_stats = pd.DataFrame(data=training_stats)\n","\n","# Use the 'epoch' as the row index.\n","df_stats = df_stats.set_index('epoch')\n","\n","# A hack to force the column headers to wrap.\n","#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n","\n","# Display the table.\n","df_stats"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"id":"94JrWc6oUklj","executionInfo":{"status":"ok","timestamp":1669691832996,"user_tz":420,"elapsed":33,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}},"outputId":"15550441-d74c-4a41-8d27-b5de504c8974"},"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n","epoch                                                                         \n","1               0.85         0.77           0.58       0:01:41         0:00:07\n","2               0.75         0.75           0.68       0:01:38         0:00:07\n","3               0.65         0.71           0.72       0:01:38         0:00:07\n","4               0.55         0.82           0.73       0:01:38         0:00:07\n","5               0.57         0.85           0.75       0:01:38         0:00:07\n","6               0.43         0.85           0.77       0:01:38         0:00:07\n","7               0.39         0.89           0.75       0:01:38         0:00:07"],"text/html":["\n","  <div id=\"df-691f2d5d-ba7f-47f0-ac2d-a1397b785b30\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Training Loss</th>\n","      <th>Valid. Loss</th>\n","      <th>Valid. Accur.</th>\n","      <th>Training Time</th>\n","      <th>Validation Time</th>\n","    </tr>\n","    <tr>\n","      <th>epoch</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.85</td>\n","      <td>0.77</td>\n","      <td>0.58</td>\n","      <td>0:01:41</td>\n","      <td>0:00:07</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.75</td>\n","      <td>0.75</td>\n","      <td>0.68</td>\n","      <td>0:01:38</td>\n","      <td>0:00:07</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.65</td>\n","      <td>0.71</td>\n","      <td>0.72</td>\n","      <td>0:01:38</td>\n","      <td>0:00:07</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.55</td>\n","      <td>0.82</td>\n","      <td>0.73</td>\n","      <td>0:01:38</td>\n","      <td>0:00:07</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.57</td>\n","      <td>0.85</td>\n","      <td>0.75</td>\n","      <td>0:01:38</td>\n","      <td>0:00:07</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.43</td>\n","      <td>0.85</td>\n","      <td>0.77</td>\n","      <td>0:01:38</td>\n","      <td>0:00:07</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.39</td>\n","      <td>0.89</td>\n","      <td>0.75</td>\n","      <td>0:01:38</td>\n","      <td>0:00:07</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-691f2d5d-ba7f-47f0-ac2d-a1397b785b30')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-691f2d5d-ba7f-47f0-ac2d-a1397b785b30 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-691f2d5d-ba7f-47f0-ac2d-a1397b785b30');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["# CELL EXTRACTED FROM SAMPLE NOTEBOOK PROVIDED\n","\n","# Display floats with two decimal places.\n","pd.set_option('precision', 2)\n","\n","# Create a DataFrame from our training statistics.\n","df_stats = pd.DataFrame(data=training_stats)\n","\n","# Use the 'epoch' as the row index.\n","df_stats = df_stats.set_index('epoch')\n","\n","# A hack to force the column headers to wrap.\n","#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n","\n","# Display the table.\n","df_stats"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"id":"Ll-BTpkcUwMy","executionInfo":{"status":"ok","timestamp":1669691832996,"user_tz":420,"elapsed":13,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}},"outputId":"af5405e0-6bc2-49f8-da19-68531baaed2b"},"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n","epoch                                                                         \n","1               0.85         0.77           0.58       0:01:41         0:00:07\n","2               0.75         0.75           0.68       0:01:38         0:00:07\n","3               0.65         0.71           0.72       0:01:38         0:00:07\n","4               0.55         0.82           0.73       0:01:38         0:00:07\n","5               0.57         0.85           0.75       0:01:38         0:00:07\n","6               0.43         0.85           0.77       0:01:38         0:00:07\n","7               0.39         0.89           0.75       0:01:38         0:00:07"],"text/html":["\n","  <div id=\"df-ba2f0393-04f5-4ebb-94e2-5396adf26d30\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Training Loss</th>\n","      <th>Valid. Loss</th>\n","      <th>Valid. Accur.</th>\n","      <th>Training Time</th>\n","      <th>Validation Time</th>\n","    </tr>\n","    <tr>\n","      <th>epoch</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.85</td>\n","      <td>0.77</td>\n","      <td>0.58</td>\n","      <td>0:01:41</td>\n","      <td>0:00:07</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.75</td>\n","      <td>0.75</td>\n","      <td>0.68</td>\n","      <td>0:01:38</td>\n","      <td>0:00:07</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.65</td>\n","      <td>0.71</td>\n","      <td>0.72</td>\n","      <td>0:01:38</td>\n","      <td>0:00:07</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.55</td>\n","      <td>0.82</td>\n","      <td>0.73</td>\n","      <td>0:01:38</td>\n","      <td>0:00:07</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.57</td>\n","      <td>0.85</td>\n","      <td>0.75</td>\n","      <td>0:01:38</td>\n","      <td>0:00:07</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.43</td>\n","      <td>0.85</td>\n","      <td>0.77</td>\n","      <td>0:01:38</td>\n","      <td>0:00:07</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.39</td>\n","      <td>0.89</td>\n","      <td>0.75</td>\n","      <td>0:01:38</td>\n","      <td>0:00:07</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba2f0393-04f5-4ebb-94e2-5396adf26d30')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ba2f0393-04f5-4ebb-94e2-5396adf26d30 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ba2f0393-04f5-4ebb-94e2-5396adf26d30');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"metadata":{"id":"7ASPVBXmUxd0","executionInfo":{"status":"ok","timestamp":1669691832996,"user_tz":420,"elapsed":12,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["# CELL EXTRACTED FROM SAMPLE NOTEBOOK PROVIDED\n","\n","# Use plot styling from seaborn.\n","sns.set(style='darkgrid')\n","\n","# Increase the plot size and font size.\n","sns.set(font_scale=1.5)\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","# Plot the learning curve.\n","plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n","plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n","\n","# Label the plot.\n","plt.title(\"Training & Validation Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.xticks([1, 2, 3, 4])\n","\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":427},"id":"_euH5a_vVmKv","executionInfo":{"status":"ok","timestamp":1669691832996,"user_tz":420,"elapsed":12,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}},"outputId":"6cc1b99e-43b9-48cd-baf3-36bd334cbb48"},"execution_count":40,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 864x432 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAuUAAAGaCAYAAACopj13AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd1xUV/4+8GcGplCG3ntRiiAIKtZYsGE3lmg0GmNiymbLz93sqhuzu0k2yXddszFl424SN80WxV6jwZIYC7FEo4IiSK/S+7T7+wMYHQEdFJgBnvduXsCde++cmeMMD2c+51yRIAgCiIiIiIjIaMTGbgARERERUU/HUE5EREREZGQM5URERERERsZQTkRERERkZAzlRERERERGxlBORERERGRkDOVE1G1lZ2cjODgYH3744UOfY8WKFQgODm7HVnVfrT3fwcHBWLFihUHn+PDDDxEcHIzs7Ox2b9+OHTsQHByMs2fPtvu5iYgelbmxG0BEPUdbwm1CQgK8vLw6sDVdT01NDf7zn//gwIEDKCwshIODA/r3749f/epXCAwMNOgcv/3tb/Htt99i165dCA0NbXEfQRAwZswYVFRU4OTJk5DL5e35MDrU2bNnkZiYiKeffho2NjbGbk4z2dnZGDNmDBYsWIC//OUvxm4OEZkQhnIi6jSrV6/W+/n8+fP45ptvMHfuXPTv31/vNgcHh0e+P09PT1y+fBlmZmYPfY4333wTr7/++iO3pT2sWrUK+/fvx5QpUxATE4OioiIcPXoUly5dMjiUz549G99++y22b9+OVatWtbjPmTNnkJOTg7lz57ZLIL98+TLE4s75YDYxMREfffQRHn/88WahfPr06Zg8eTIkEkmntIWIqC0Yyomo00yfPl3vZ41Gg2+++Qb9+vVrdtu9qqqqYG1t3ab7E4lEkMlkbW7n3UwlwNXW1uLQoUMYPnw43n33Xd32X//611AqlQafZ/jw4XB3d8fevXvxpz/9CVKptNk+O3bsANAQ4NvDo/ZBezEzM3ukP9CIiDoSa8qJyOTExsZi4cKFuHbtGp599ln0798f06ZNA9AQzt977z3MmTMHgwYNQnh4OMaNG4c1a9agtrZW7zwt1Tjfve3YsWOYNWsW+vbti+HDh+Mf//gH1Gq13jlaqilv2lZZWYm//vWvGDJkCPr27Yt58+bh0qVLzR5PaWkpVq5ciUGDBiEqKgqLFi3CtWvXsHDhQsTGxhr0nIhEIohEohb/SGgpWLdGLBbj8ccfR1lZGY4ePdrs9qqqKhw+fBhBQUGIiIho0/PdmpZqyrVaLf773/8iNjYWffv2xZQpU7Bnz54Wj09NTcXf/vY3TJ48GVFRUYiMjMTMmTOxbds2vf1WrFiBjz76CAAwZswYBAcH6/V/azXlJSUleP311zFy5EiEh4dj5MiReP3111FaWqq3X9Pxp0+fxvr16zF27FiEh4djwoQJ2Llzp0HPRVskJyfj5ZdfxqBBg9C3b19MmjQJn376KTQajd5+eXl5WLlyJUaPHo3w8HAMGTIE8+bN02uTVqvFF198galTpyIqKgrR0dGYMGEC/vznP0OlUrV724mo7ThSTkQmKTc3F08//TTi4uIwfvx41NTUAAAKCgoQHx+P8ePHY8qUKTA3N0diYiI+++wzJCUlYf369Qad/8SJE9i0aRPmzZuHWbNmISEhAf/73/9ga2uLF1980aBzPPvss3BwcMDLL7+MsrIyfP7553j++eeRkJCgG9VXKpV45plnkJSUhJkzZ6Jv3764fv06nnnmGdja2hr8fMjlcsyYMQPbt2/Hvn37MGXKFIOPvdfMmTOxbt067NixA3FxcXq37d+/H3V1dZg1axaA9nu+7/XOO+/gq6++wsCBA7F48WIUFxfjjTfegLe3d7N9ExMTce7cOYwaNQpeXl66Tw1WrVqFkpISvPDCCwCAuXPnoqqqCkeOHMHKlSthb28P4P5zGSorK/Hkk08iIyMDs2bNQp8+fZCUlITNmzfjzJkz2LZtW7NPaN577z3U1dVh7ty5kEql2Lx5M1asWAEfH59mZVgP65dffsHChQthbm6OBQsWwMnJCceOHcOaNWuQnJys+7RErVbjmWeeQUFBAebPnw8/Pz9UVVXh+vXrOHfuHB5//HEAwLp16/DBBx9g9OjRmDdvHszMzJCdnY2jR49CqVSazCdCRD2aQERkJNu3bxeCgoKE7du3620fPXq0EBQUJGzdurXZMfX19YJSqWy2/b333hOCgoKES5cu6bZlZWUJQUFBwgcffNBsW2RkpJCVlaXbrtVqhcmTJwvDhg3TO+/y5cuFoKCgFrf99a9/1dt+4MABISgoSNi8ebNu24YNG4SgoCDh448/1tu3afvo0aObPZaWVFZWCkuXLhXCw8OFPn36CPv37zfouNYsWrRICA0NFQoKCvS2P/HEE0JYWJhQXFwsCMKjP9+CIAhBQUHC8uXLdT+npqYKwcHBwqJFiwS1Wq3bfuXKFSE4OFgICgrS65vq6upm96/RaISnnnpKiI6O1mvfBx980Oz4Jk3/3s6cOaPb9q9//UsICgoSNmzYoLdvU/+89957zY6fPn26UF9fr9uen58vhIWFCcuWLWt2n/dqeo5ef/31++43d+5cITQ0VEhKStJt02q1wm9/+1shKChIOHXqlCAIgpCUlCQEBQUJn3zyyX3PN2PGDGHixIkPbB8RGQ/LV4jIJNnZ2WHmzJnNtkulUt2onlqtRnl5OUpKSjB06FAAaLF8pCVjxozRW91FJBJh0KBBKCoqQnV1tUHnWLx4sd7PgwcPBgBkZGToth07dgxmZmZYtGiR3r5z5syBQqEw6H60Wi1+97vfITk5GQcPHsSIESPwyiuvYO/evXr7vfbaawgLCzOoxnz27NnQaDTYtWuXbltqaip+/vlnxMbG6ibattfzfbeEhAQIgoBnnnlGr8Y7LCwMw4YNa7a/paWl7vv6+nqUlpairKwMw4YNQ1VVFdLS0trchiZHjhyBg4MD5s6dq7d97ty5cHBwwHfffdfsmPnz5+uVDLm6usLf3x/p6ekP3Y67FRcX4+LFi4iNjUVISIhuu0gkwksvvaRrNwDdv6GzZ8+iuLi41XNaW1ujoKAA586da5c2ElH7Y/kKEZkkb2/vViflbdy4EVu2bMHNmzeh1Wr1bisvLzf4/Peys7MDAJSVlcHKyqrN52gqlygrK9Nty87OhouLS7PzSaVSeHl5oaKi4oH3k5CQgJMnT+Kf//wnvLy88P777+PXv/41/vSnP0GtVutKFK5fv46+ffsaVGM+fvx42NjYYMeOHXj++ecBANu3bwcAXelKk/Z4vu+WlZUFAAgICGh2W2BgIE6ePKm3rbq6Gh999BEOHjyIvLy8ZscY8hy2Jjs7G+Hh4TA31/91aG5uDj8/P1y7dq3ZMa3928nJyXnodtzbJgDo1atXs9sCAgIgFot1z6GnpydefPFFfPLJJxg+fDhCQ0MxePBgxMXFISIiQnfc73//e7z88stYsGABXFxcEBMTg1GjRmHChAltmpNARB2HoZyITJKFhUWL2z///HP83//9H4YPH45FixbBxcUFEokEBQUFWLFiBQRBMOj891uF41HPYejxhmqamDhw4EAADYH+o48+wksvvYSVK1dCrVYjJCQEly5dwltvvWXQOWUyGaZMmYJNmzbhwoULiIyMxJ49e+Dm5obHHntMt197Pd+P4g9/+AOOHz+OJ554AgMHDoSdnR3MzMxw4sQJfPHFF83+UOhonbW8o6GWLVuG2bNn4/jx4zh37hzi4+Oxfv16PPfcc/jjH/8IAIiKisKRI0dw8uRJnD17FmfPnsW+ffuwbt06bNq0SfcHKREZD0M5EXUpu3fvhqenJz799FO9cPT9998bsVWt8/T0xOnTp1FdXa03Wq5SqZCdnW3QBW6aHmdOTg7c3d0BNATzjz/+GC+++CJee+01eHp6IigoCDNmzDC4bbNnz8amTZuwY8cOlJeXo6ioCC+++KLe89oRz3fTSHNaWhp8fHz0bktNTdX7uaKiAsePH8f06dPxxhtv6N126tSpZucWiURtbsutW7egVqv1RsvVajXS09NbHBXvaE1lVTdv3mx2W1paGrRabbN2eXt7Y+HChVi4cCHq6+vx7LPP4rPPPsOSJUvg6OgIALCyssKECRMwYcIEAA2fgLzxxhuIj4/Hc88918GPiogexLT+3CciegCxWAyRSKQ3QqtWq/Hpp58asVWti42NhUajwVdffaW3fevWraisrDToHCNHjgTQsOrH3fXiMpkM//rXv2BjY4Ps7GxMmDChWRnG/YSFhSE0NBQHDhzAxo0bIRKJmq1N3hHPd2xsLEQiET7//HO95f2uXr3aLGg3/SFw74h8YWFhsyURgTv154aW1YwdOxYlJSXNzrV161aUlJRg7NixBp2nPTk6OiIqKgrHjh3DjRs3dNsFQcAnn3wCABg3bhyAhtVj7l3SUCaT6UqDmp6HkpKSZvcTFhamtw8RGRdHyomoS4mLi8O7776LpUuXYty4caiqqsK+ffvaFEY705w5c7BlyxasXbsWmZmZuiURDx06BF9f32brordk2LBhmD17NuLj4zF58mRMnz4dbm5uyMrKwu7duwE0BKx///vfCAwMxMSJEw1u3+zZs/Hmm2/ihx9+QExMTLMR2I54vgMDA7FgwQJs2LABTz/9NMaPH4/i4mJs3LgRISEhenXc1tbWGDZsGPbs2QO5XI6+ffsiJycH33zzDby8vPTq9wEgMjISALBmzRpMnToVMpkMvXv3RlBQUIttee6553Do0CG88cYbuHbtGkJDQ5GUlIT4+Hj4+/t32AjylStX8PHHHzfbbm5ujueffx6vvvoqFi5ciAULFmD+/PlwdnbGsWPHcPLkSUyZMgVDhgwB0FDa9Nprr2H8+PHw9/eHlZUVrly5gvj4eERGRurC+aRJk9CvXz9ERETAxcUFRUVF2Lp1KyQSCSZPntwhj5GI2sY0f4sREbXi2WefhSAIiI+Px1tvvQVnZ2dMnDgRs2bNwqRJk4zdvGakUim+/PJLrF69GgkJCTh48CAiIiLwxRdf4NVXX0VdXZ1B53nrrbcQExODLVu2YP369VCpVPD09ERcXByWLFkCqVSKuXPn4o9//CMUCgWGDx9u0HmnTp2K1atXo76+vtkET6Djnu9XX30VTk5O2Lp1K1avXg0/Pz/85S9/QUZGRrPJlf/85z/x7rvv4ujRo9i5cyf8/PywbNkymJubY+XKlXr79u/fH6+88gq2bNmC1157DWq1Gr/+9a9bDeUKhQKbN2/GBx98gKNHj2LHjh1wdHTEvHnz8Jvf/KbNV5E11KVLl1pcuUYqleL5559H3759sWXLFnzwwQfYvHkzampq4O3tjVdeeQVLlizR7R8cHIxx48YhMTERe/fuhVarhbu7O1544QW9/ZYsWYITJ07g66+/RmVlJRwdHREZGYkXXnhBb4UXIjIekdAZs3SIiEiPRqPB4MGDERER8dAX4CEiou6DNeVERB2spdHwLVu2oKKiosV1uYmIqOdh+QoRUQdbtWoVlEoloqKiIJVKcfHiRezbtw++vr544oknjN08IiIyASxfISLqYLt27cLGjRuRnp6OmpoaODo6YuTIkfjd734HJycnYzePiIhMAEM5EREREZGRsaaciIiIiMjIGMqJiIiIiIyMEz0blZZWQ6vt3EoeR0drFBdXdep90oOxX0wP+8Q0sV+IiNpGLBbB3t6qxduMGsqVSiXef/997N69GxUVFQgJCcGyZct0Vyq7n127dmH9+vVIT0+Hra0t4uLisGzZMlhZtfxAH0SrFTo9lDfdL5ke9ovpYZ+YJvYLEVH7MGr5yooVK/Dll19i2rRpePXVVyEWi7F06VJcvHjxvsd9+eWXWL58OZydnbFixQrMnDkT8fHx+NWvfgXOWyUiIiKirsZoI+WXL1/G/v37sXLlSixevBgAMGPGDEyZMgVr1qzBxo0bWzxOqVTiww8/xODBg7F+/XqIRCIAQFRUFF588UUkJCRg7NixnfUwiIiIiIgemdFGyg8dOgSJRII5c+botslkMsyePRvnz59HYWFhi8elpKSgsrISkyZN0gVyABg9ejQsLS1x4MCBDm87EREREVF7MlooT0pKgr+/f7Ma8IiICAiCgKSkpBaPUyqVABoC/L3kcjmuXr3a/o0lIiIiIupARgvlRUVFcHFxabbd2dkZAFodKff19YVIJMKFCxf0tqelpaGkpKTV44iIiIiITJXRasrr6uogkUiabW8aAa+vr2/xOAcHB0ycOBHbt29HQEAAxowZg4KCArz55puQSCStHvcgjo7WD3Xco3J2Vhjlfun+2C+mh31imtgvRETtw2ihXC6XQ6VSNdveFKpbKk9p8sYbb6Curg7vvPMO3nnnHQDAtGnT4OPjg9OnTz9Ue4qLqzp9aS9nZwWKiio79T7pwdgvpod9YprYL0REbSMWi1odCDZaKHd2dm6x1KSoqAgAWixtaaJQKLBu3Trk5uYiJycHHh4e8PT0xLx58+Dr69thbSYiIiIi6ghGqykPCQnBrVu3UF1drbf90qVLutsfxMPDAwMHDoSnpycqKipw5coVgy48RERERERkSowWyuPi4qBSqbBt2zbdNqVSiR07diA6Ohqurq4AgNzcXKSmpj7wfO+++y7EYjHmzp3bYW0mIiIioq4rMf8CVv34Nl4++ies+vFtJOZfePBBncRo5SuRkZGIi4vDmjVrUFRUBB8fH+zcuRO5ubm6OnEAWL58ORITE3H9+nXdtnXr1iE1NRWRkZEwMzNDQkICTp48iTfeeAPe3t7GeDhEREREZMIS8y9gU/J2qLQNcxpL68uwKXk7ACDGLdqYTQNgxFAOAKtXr8batWuxe/dulJeXIzg4GJ988gn69+9/3+OCg4ORkJCAhIQEAEBYWBg+/fRTjBgxojOaTURERERdSI2qFjtS9ukCeROVVoU9qYdMIpSLBEHo3CVHTBRXX6Em7BfTwz4xTewXIjJFSo0SWZW5yKjMQkZFFjIrslFYe/u+x/w7dnWntM0kV18hIiIiInoUGq0GOdV5yKjIRmZFFjIqs5FXXQCtoAUA2Mls4avwwiD3/jie9SMqVVXNzmEvs+vsZreIoZyIiIiITJ5W0KKwpggZFdmNo+DZyK7KhVqrBgBYmVvCx8YLfR1D4WvjDR8bL9jJbHXHO8jt9WrKAUAilmBaYFynP5aWMJQTERERkUkRBAEldWXIqGwoP0mvyERWZQ7qNA0XmZSaSeFt7YkRnkPga+MNX4U3nCwcIBKJWj1nU934ntRDKK0vg73MDtMC40yinhxgKCciIiIiI6tQViKzIhsZjSUoGRVZqFI1XMvGTGQGT2t3DHSLhq/CC7423nCzcoFY1PaVvWPcok0mhN+LoZyIiIiIOk2tuhaZFTm6EpSMiiyU1pcBAEQQwc3KBeGOofC1aQjgHtbukIi7f2Tt/o+QiIiIiIxCqVEhuyq3YQS8IhuZlVkoqCnS3e4kd0CArS98bIbBV+ENb4Un5OYyI7bYeBjKiYiIiOiRabQa5FYXNK6C0hDCc6vzdSuh2EoV8LHxxkDXaPjaeMHHxgvWEisjt9p0MJQTERERUZtoBS2Kam7r6r8bVkLJgapxJRRLcwv4KLwwzmeUrgzl7pVQqDmGciIiIiJqlSAIKK0v09V/Z1RmI7MiG3WaOgCAVCyBt8ITj3kOga/CCz423nC2cLzvSijUHEM5EREREelUKqvuCt8No+BNF91pWAnFDQPc+sFX4Q1fGy+4WbrATGxm5FZ3fQzlRERERD1UrboOWZXZeqPgJXWlABpWQnG1ckEfx+CGtcBtvOBp5Q6JmcTIre6eGMqJiIiIegCVbiWUO1fELKwpggABAOAod4CfjTdGeg2Fr8KrcSUUuZFb3XMwlBMRERF1MxqtBnnVBbrwnVmRhZy7VkKxkSrga+OFga794GPjDV+FF6ylXAnFmBjKiYiIiLowraBFUW0xMioaLkmfUZmFrMpcqLQqAICFuQV8FV4Y6zOy8ZL0XrCT2XIipolhKCciIiLqIgRBQFl9ud7l6DMrs1GrblgJRdK4Espwz0G6iZjOFk4M4F0AQzkRERGRiapSVjeWoGTpasErlQ0roYhFYnhau6O/S2TjRExvroTShTGUExEREZmAOnUdMitz9JYjLL57JRRLZ/RxCIaPjRd8Fd7wsuZKKN0JQzkRERFRB0jMv4A9qYdQWl8Ge5kdpgXGIcYtGkDTSih5yKhsrAOvyEKB3koo9vCx8W64II+NN7wVnrDgSijdGkM5ERFRF3e/8EfGkZh/AZuSt+smW5bWl2FD0jaczv0JtZo65FblQyNoAAAKqTV8Fd7o79pQhuKj8IJCam3M5pMRMJQbwemr+dhxIhUlFfVwsJFh5shADAlzM3aziIioC2op/G1MjkdpXRnCnUKhFQQI0AICIDT9T2j6Cr2fAaFxfwEQAG3jtjv7N50BzbZBEBr3b37bne8bbgMa9m34HhAE3T3dc2xL+991W4ttu9P2u49FK4/5zjatru16+9/n8bS8f8NtGRVZUDeG7iYaQYOUslQE2ffCGJ8R8FV4wdfGmyuhEACG8k53+mo+vjyYDKW64cVfXFGPLw8mAwCDORERPVDT6hvZVbnIrszDtxlHdYG8iVqrxp60Q9iTdshIrew4IjSEV5FIBBFEjV9x1/eixoArglj3/V3737Nf07EQNezf8H9xq+dtOjNEaNhf7/aG/cUicbNA3kQA8Nuo5zv+iaIuh6G8k+04kaoL5E2Uai12nEhlKCciIj1qrRr51YXIrspFTlUesisbvlaraww6fmn4wjsBtSmcNguZ+oGyKWSKRbpIqrutpWALAOKm75vdfm94vtMWUWMA1g+2gEgkhm5PvZANve9N3aof30ZpfVmz7fYyOyO0hroChvJOVlxR3+r2mjo1LOXsEiKinqhKVY2cyjzkVOUiuyoP2VW5yK8u1NUdS8Tm8LByRz+XcHhae8DL2gMe1m546+y/Wg1//Vz6dvbDoEbTAuP0yoqAhjXEpwXGGbFVZMqYADuZo42s1WD+509O4/ERAXgswgNicdcYCSAiorbRClrcri1GdlUecipzG8pQqvJQVl+u28dGqoCXtQf6OATDS+EBL2t3OFs4tbj+NMOfaWqaaMsJuGQokdA0U6GHKy6uglbb8U/FvTXlACA1F2PyEF/8cqsEN7PL4eNijSfH9kawj32Ht4eac3ZWoKio0tjNoLuwT0wT++XB6jVK5Fbl6Ua+cyrzkFOdB6VGCaDh4i+uls7wsvaAp7V7YwD3aPPKG1x9hahrEItFcHRs+fXNUN6os0I50PrqK4Ig4KfkQmw7dhPFFfXoH+SMObG94GJn0SntogYMGqaHfWKa2C93CIKAcmUFsivvlJ7kVOWiqKZYt+603EwOL4W7rvTEy9od7lauvPgLUQ/CUG6AzgzlTVr7haZUafBtYib2n8mAVitg/EAfTB7iCwsZq406A4OG6WGfmKae2i8arQb5NYWNAbxxAmZVLqpVdyZfOsod4KVoHP1uDOAOcvsuM0mRiDrG/UI5U54JkkrMMHWYP4ZHeGD7iVQcOJOBk7/kYdaIAAyLcNfNoCcioo5Vraq5M/GyceWTvOoC3eRLc7E5PKzcEOkUBs/G0hNPazdYmPMTTiJqG46UNzKlkfJ7peVWYHPCDaTmVMDXVYEnx/ZGkDeXVOooPXX0z5SxT0xTd+qXhsmXJbpR75zGNcDvXtVEIbVuHPW+U//t0srkSyKilrB8xQCmHMqBhnrFs9cKsO14Kkor6zEgxAVPjAqEE+vN2113ChrdBfvENHXVflFqlMipykfOXaUnOVV5qG+cfCmCCK5WLvBqLD3xtG6oA7eVKYzcciLq6li+0g2IRCIMDnNDVJAzDp3NxMEzGfg55TbiBnlj0mBfyKXsSiKiuzVNvrz7ojvZVbkorLl91+RLGTyt3THYfYCu/tvdyg1STr4kok7GJNfFyCRmmD7cH49FuCP+eCr2ncrAD5fzMHtkIIaEu7HenIh6pKbJlzl3LT2YXZWLKlW1bh9HuT08rT3Q3yWysf67YfKlWCQ2YsuJiBqwfKWRqZevtOZmTjk2f5eCW3kV8HdX4MkxQejlZdtOLeyZuupH8t0Z+8Q0GatfalS1ele9zKnMRV51AdR3Tb50t3K9U/vd+NVSwnI/IjIu1pQboKuGcgDQCgLOXM1H/PFUlFUpMaiPK2aPDISjrbwdWtnzMACaHvaJaeroftEKWhTXluoH8Ko8lNSV6vaxllg1TL68a/lBV0tnTr4kIpPEmvJuTiwSYWi4O/oHueDAmQwcSszExRtFiBvkg4mDfCGT8pcTEZk2pUaFvOp8vYvv5FbloU5TD6Bh8qWLpTP8bXzwmMdgXfmJjVTBtb+JqFtgKO9GZFIzPD4iAI9FNtSb7/kxXVdvPijMlfXmRGQSyusr71p2sGH0u6CmSDf5UmYmhae1B2LcohtKTxTu8LByg9RMauSWExF1HJavNOrK5SutSckuw6bvUpCRX4kADxs8ObY3Aj1Yb/4gLJUwPewT05KYfwF7Ug+hrL4MdjI7TAuMQ4xbdLP9NFoNCmqK9JYdzK7MRaWqSrePvcwOXo2j3g213x5wtODkSyLqnlhTboDuGMqBhnrzU7/kY/uJVJRXKzEkzBWzR/WCvULWoffblTEAmh72ielIzL+ATcnbodKqdNskYglm954KV0sXvYvv5FYXQK1VAwDMRWZwt3KFp179tzssJZbGeihERJ2OodwA3TWUN6mtV+PAmQx8m5gFsRiYNMgXEwb5QCZhvfm9GABND/vEdKz68W29q1y2pGnyZdNVLz2t3eFm6cLJl0TU43GiJ8FCZo5ZIwMxItID247dxK6Tt/D95VzMGdULMaEunChFRAa5XyB/KeIZeCk8YCu14XsKEVEbsWivh3G2s8CvHu+L5fOjYC2X4L97ruKdDRdwK6/C2E0jIhMmCALO5p2HCC2HbXuZHcKdQmEns2UgJyJ6CAzlPVSwjz3+snggFk8MQWFpDd788hzW77uG0kNO2UQAACAASURBVMp6YzeNiExMaV0ZPr78P3yV9A2cLBwgEet/yCoRSzAtMM5IrSMi6h5YvtKDicUijIj0wMAQF+w7lY4j57Jw7noRJg3xxYSB3pCy3pyoR9MKWvyYm4hdN/dDK2gxu/c0jPQainMFPxu0+goRERmOEz0bdfeJnoYoLK3B1mOpuHCjCI42cjwR2wsDgp173EfRptYvxD4xhqKaYmxKjseNslQE2ffCgpBZcLJw1NuH/UJE1Dac6EkGcbG3xK9n9kVSRik2f5eCdbuuIMjLFk+ODYKvm8LYzSOiTqAVtDiRfQp7Ug9CLBJjfvAsDPWI6XF/nBMRdTajjpQrlUq8//772L17NyoqKhASEoJly5ZhyJAhDzz21KlTWLduHW7cuAGtVouAgAA8/fTTmDRp0kO1hSPl+rRaAd9fzsXO79NQVaPCsAh3zBoRAFvr7r++uSn3S0/FPukc+dWF2JC0DbcqMhDmGIIng2fCXm7X6v7sFyKitjHZkfIVK1bg8OHDWLRoEXx9fbFz504sXboUX3/9NaKiolo97tixY3jppZcQFRWF3/zmNwCA/fv3Y9myZaiursacOXM66yF0W2KxCKP6eSImxBV7T93Cd+ey8VNyIaYM8cX4gd6QmLPenKi70Gg1+C7zBA6kfweZWIqn+8zDQNcojo4TEXUio42UX758GXPmzMHKlSuxePFiAEB9fT2mTJkCFxcXbNy4sdVjn3vuOVy/fh0JCQmQSqUAGkbdx4wZA19fX2zYsKHN7eFI+f0VlNTgm6M38fPN23CylWNubC9EB3XPevOu1C89Bfuk42RX5mJD8jZkVeagn3NfzA2eARupYeVq7Bciora530i50ZZEPHToECQSid6otkwmw+zZs3H+/HkUFha2emxVVRVsbW11gRwApFIpbG1tIZN1//IKY3B1sMRvZ0fgD3P7QSYxw793XsE/N19EZgF/IRN1RSqtGvvSvsU/zn2AsrpyPBv+FJb2XWhwICciovZltFCelJQEf39/WFlZ6W2PiIiAIAhISkpq9diYmBikpKRg7dq1yMzMRGZmJtauXYv09HQsWbKko5veo4X5O+BvSwZi4fggZBdV4/XPf8IXB5NRUa00dtOIyEDpFZn4x0/v42B6Avq79MOqwX9AtEuEsZtFRNSjGa2mvKioCK6urs22Ozs7A8B9R8pffPFFZGZm4j//+Q/WrVsHALC0tMTHH3+MYcOGdUyDScdMLMboaC/E9HHFnpPpOHohGz8lF2DqUH+M6e8FiTmvSUVkipQaFfbfOoyEzO9hK7PBSxHPINwp1NjNIiIiGDGU19XVQSKRNNveVH5SX9/6lSWlUin8/PwQFxeHcePGQaPRYOvWrfh//+//4YsvvkBERNtHfFqr7+lozs5d96NiZwC/fdIBj8f2xv/2XsXWYzfxw+U8LJkWhkFhbl263rwr90t3xT55NElFKfjP+Q3IqyrEmIDhWBg5E5ZSi0c+L/uFiKh9GC2Uy+VyqFSqZtubwvj9asPffPNN/PLLL4iPj4dY3DAqO3HiREyZMgVvv/02tmzZ0ub2cKLnw5OLgV9ND8OVvm7YnJCCtz5PRKivPZ4c0xteLsb5Y+dRdJd+6U7YJw+vTl2PPWkHcSL7FBzlDvhNv6UIceiN6nI1qvFozyn7hYiobUxySURnZ+cWS1SKiooAAC4uLi0ep1QqER8fjxdeeEEXyAFAIpHgsccew+bNm6FWq2FuzusidbbwAEe87muPEz/nYtcPafjr54kY2c8TMx7zh42l9MEnIKJ2lVRyA5uSt6O0rgyjvIZhakAc5OacDE9EZIqMllxDQkLw9ddfo7q6Wm+y56VLl3S3t6SsrAxqtRoajabZbWq1Gmq1Gka8HlKPZ24mxpj+XhjUxxW7T97CsQs5OHutANOG+WFMfy+Ym7HenKij1ahqsePmPpzO+wkulk5YFv0SAu38jN0sIiK6D6MlpLi4OKhUKmzbtk23TalUYseOHYiOjtZNAs3NzUVqaqpuH0dHR9jY2ODIkSN65S/V1dU4duwYgoKCWqxVp85lbSHBgnFBeOPZGAR62uCbozfx2vpE/HzzNv9oIupAv9y+hr+ffRdn8s5hnM8orBy4jIGciKgLMNpIeWRkJOLi4rBmzRoUFRXBx8cHO3fuRG5uLt555x3dfsuXL0diYiKuX78OADAzM8OSJUuwdu1azJ07F9OmTYNWq0V8fDzy8/OxfPlyYz0kaoGHkxV+/0Q/XE69jS0JN/FB/GWE+TtgXmwveDp3vXpzIlNVpazGtpTdOFfwMzys3PBCxNPwtfE2drOIiMhARruiJ9AwqXPt2rXYu3cvysvLERwcjN///vcYOnSobp+FCxfqhfIme/fuxVdffYX09HQolUoEBwdj6dKlGDdu3EO1hRM9O55ao8WxCznYffIW6pQajIrywIzHAmBtYVqfbPS0fukK2CetEwQBFwovY+uNXahV12GCXywm+I6Gubjjx1zYL0REbXO/iZ5GDeWmhKG881TWKLHr5C0cv5gDC6k5pg/3x+hoT5OpN++p/WLK2CctK6+vwDc3duFS0RX4KLzwVOgceFq7d9r9s1+IiNrGJFdfoZ5LYSnFwvHBGB3liS0JKdickILjP+dgbmxvRAQ6Grt5RCZPEASczT+P+JS9UGlVmBE4CbHej8FMbGbsphER0UNiKCej8XK2xh/m9sOlm8X45mgK1m67hL4Bjpgb2wseTlYPPgFRD1RSV4rNyTtwreQ6Amz98FTIbLhatbyELBERdR0M5WRUIpEI/Xo7ITzAAd+dy8beU7fwl/WJiI32xLTh/iZXb05kLFpBix9zz2Lnzf0QBAFzek/HCK8hEItMo+yLiIgeDUM5mQRzMzHiBvlgaLgbdv2QhoQL2Th9NR8zHgvAqCgPmIkZPKjnKqopxsbkbUgpS0OwfS/MD5kNJwsHYzeLiIjaEUM5mRQbKykWxYVgdLQXNn93AxuP3MCxizmYN6YXwv1Zb049i1bQ4njWSexJ+xZmIjPMD5mFoe4xEIlExm4aERG1M4ZyMkneLtb445NRuJhyG98cTcG/vrmEyEBHzB3TG24OlsZuHlGHy68uwIakbbhVkYlwx1DMC34c9nI7YzeLiIg6CEM5mSyRSIToIGf0DXDEd+eysPdUOl777CzG9PfCtGF+sJSz3py6H41WgyOZJ3Dw1hHIzGR4us88DHSN4ug4EVE3x1BOJk9iLsbEwb4Y2tcdO06k4shPWTh1JR+PjwjAiEh31ptTt5FVmYuNSVuRVZWLKOe+eCJ4BmykCmM3i4iIOgEvHtSoMy8elJh/AXtSD6Gsvgx2MjtMC4xDjFt0p9x3d5CRX4nNCSm4kVUGL2crzBvTG3382m/SGy+IYnq6e5+otGp8m56AbzOOwUpiiblBjyPKpa+xm/VA3b1fiIjaG6/oaYDOCuWJ+RewKXk7VFqVbptELMH8kFkM5m0gCALOXy/C1mM3cbu8DlG9nfBEbC+42j96vTmDhunpzn1yqzwTG5K3Ib+6AIPc+mNW76mwknSNeRPduV+IiDoCr+hpQvakHtIL5ACg0qqwJ/UgQ3kbiEQiDAhxQWQvRxz+KQv7TmVg1adnMW6AN6YM9YOlnP+0ybQpNUrsu3UYRzN/gK3MBi9FPINwp1BjN4uIiIyEI+WNOmuk/OWjf2r1NmuJFRzkdnCQO8BRbg8HuT0cLRq+OsjtYWEu7/D2dVVlVfXYcSINP/6SB4WlBI+PCMBjER4Qi9s+OY6jf6anu/VJSmkaNiZvQ1FtMYZ7DMKMXpO75Ou7u/ULEVFH40i5CbGX2aG0vqzZdgtzOfo5h6Okrgx51QW4WpwElVatt4+luUVDUJfbw6ExrDeEdwc4yu1gYW7RY1dosLOWYcnkUMT298Sm71Lw5aHrOHohB0+O6Y0QX3tjN48IAFCnrsPu1IP4Puc0HOUO+G2/5xHs0MvYzSIiIhPAkfJGplZTLggCqlTVKK4rQXFtKUrqGv4rvuurUqPUO7fcTA4HuV3j6LpDw/d3jbpbSSx7RGgXBAE/JRdi27GbKK6oR/8gZ8yJ7QUXOwuDjufon+npDn2SVHwDG5PjUVZfjlFewzA1MA4yM6mxm/VIukO/EBF1Jk70NEBXW31FEARUq2tQUqsf1EvqSlBSV4bi2lLUaer0jpGaSXWj601B/e4SGYXEuluFdqVKg28TM7H/TAa0WgHjB/pg8hBfWMju/wERg4bp6cp9UqOqxY6b+3A67ye4WjrjqdA5CLD1M3az2kVX7hciImNgKDdAZ4byJh39C61GVasf1OtKUFJ7J8DXqGv19peIJY017XdCe0OpTMOou41UAbGo660JXlpZj+0nUnHqSj5srKSYNSIAw/q6t1pvzqBherpqn1wuuoot13egUlWNsT4jMclvLCRm3eeiV121X4iIjIWh3ADdMZQ/SK26Tr8s5q5R95K6UlSpqvX2NxeZwb6xJObeUXZHuT1sZTYmHdrTciuwOeEGUnMq4ONqjfljgxDk3fyy5cbuF2quq/VJpbIK8Sl7cK7gZ3hau+OpkDnwsfEydrPaXVfrFyIiY2MoN0BPDOUPUq9RNgT22oaR9obwfmfUvVJZpbe/WCSGvcyu2UTUplF3O5ktzMRmRno0DQRBwNlrBdh2PBWllfUYEOKCJ0YFwumuenNT75eeqKv0iSAIuFB4CVtv7Eatug4T/cZgnO8omIu755z6rtIvRESmgqHcAAzlbafUqFBad29Ne+P3taUoV1bo7S8WiWErtYGjhX3jaLv+8o/2cttOCy/1Kg0Onc3EwTMZ0ArAhBhvONvJsffHdJRU1MPBRoaZIwMxJMytU9pD99cVXivl9RX45vpOXLp9Fb4KbzwVOgce1t37309X6BciIlPCUG4AhvL2p9KqUXrvCPtdK8mU1ZdDwJ3nXAQRbGU2LdS0N05Kldm1ez1uSUUd4o+n4sy1gma3Sc3FeHpiCIO5CTDl14ogCDiTfx7bU/ZCrVVhsv94xHo/ZvRPhTqDKfcLEZEp4jrlZBQSsTlcLJ3gYunU4u0arQal9eUouWvZx6bR9rTydJwvvAStoNU7xlaq0NWz36lpb1in3UFuD2kbl5hzsJHj+WlhuJZRiopq/SUmlWotdpxIZSinVpXUlWJT8nYkldxAoK0fFoTOgauls7GbRUREXRBDORmNmdgMThYOcLJwAFq4vo9Gq0G5sqLZOu3FdaXIqMzGz0VXoBE0escoJNYNgd3Cvtk67Q5yO8hbuWpiRbUSZg65MPe+AZG0DoJSDnVWEIpLPDrioVMXpxW0OJlzFrtS90MAMCdoOkZ4DjHpic5ERGTaGMrJZJmJzXQj4i3RClpUKCtRXHunPKZp1D2nKhe/3L4G9T1XRbWSWOqVxzR9r/DLgMrxOkRmDSPzIlkdJP5XAADHL+ZgRKRHq0soUs9SWHMbm5LjkVKWhhD73pgfMguOFg7GbhYREXVxrClvxJry7kcraFGprGp2JdS712q/+8qqLRGp5Ki5OAp+bgo8NT4YAR42ndR6upspvFa0ghbHsk5ib9q3MBebYWavKRjiPrBbXXCrrUyhX4iIuhJO9DQAQ3nPIwgCqlTVKKkrxepzH7a6n42ZPaqKrVFfaoMoz96Y/1g0bK1aLoOhjmHs10pedQE2JG1DekUmwh1D8WTITNjJbI3WHlNh7H4hIupqONGTqAUikQgKqTUUUmvYy+xQWl/WbB8Lczl87dyRJkqH1i4LV3AVf/5xP1zlHhjgFYQAOz/42Xi3WqtOXZtGq8GRzBM4eOsIZOYyLO7zJAa49uvRo+NERNQxGMqJAEwLjMOm5O165SwSsQRPBM1AjFs0BEFAUe1tnM++geM3riBPWYD9t44AooalHD2t3RFg6wt/W18E2PrBUW7P4NbFZVXmYkPSVmRX5SLaJQJPBM2AQtry6AYREdGjYvlKI5avUGL+BexJPYSy+jLYyewwLTAOMW7RzfYTBAGJSYXYcvwaKkWF8AvQwMqxElnVWajXNCyraCNV6IV0b4UnJN30qo6doTNfKyqtGodufYfDmcdhJbHEvOCZ6Occ3in33dXwPYyIqG1YU24AhnJqYmi/1NarsfdUOo78lAWZxAwzHvNDUJAY6RVZSCvPwK3ydNyuKwEAmIvN4aPwQoCtry6s20gVHf1Quo3Oeq3cKs/EhuRtyK8uwCC3/pjVeyqsJJYdfr9dFd/DiIjahqHcAAzl1KSt/ZJ7uxobj9xAUkYpvF2s8dT4IPT2sgMAlNdX4lZFBtLK03GrPAOZFdlQN66t7mThqAvpAbZ+cLdy5TrXrejo14pSo8S+tMM4mvUD7GS2eDJkJsIcQzrs/roLvocREbUNQ7kBGMqpycP0iyAIOHe9CFsSUlBaWY+h4W6YM7oXbK30rzCq0qqRVZmjC+mp5emoVFYBAORmMvjZ+OhCup+tNyzMLdrtcXVlHflaSSlNxcbkeBTVFmO452DMCJwEC07cNQjfw4iI2oah3AAM5dTkUfqlTqnGvlMZ+DYxE1KJGDOGByC2vyfMxC2PgAuCgOK6Ul1ITyvPQE5VHgQIEEEEdytXXUj3t/WFs4Vjj5xA2hGvlTp1HXanHsT3OafhJHfAgtDZCLLv1a730d3xPYyIqG0Yyg3AUE5N2qNf8oqrsem7FFy9VQIvZyssGBeEYJ+Wr0x6rzp1HdIrsnQh/VZFBmrVdQAAa4kVAmz9dHXpPgovSM0kj9TWrqC9XyvXiq9jU/J2lNWXY7T3cEwJmACZmfTBB5IevocREbUNQ7kBGMqpSXv1iyAIuHCjoaSluKIeg8Nc8cToXrCzlrXpPFpBi/zqQl1IT6tIR2HNbQCAmcgM3grPu1Z68e2WF7Vprz6pUdVg+819OJN3Dq6WLngqdA4CbH3boYU9E9/DiIjahqHcAAzl1KS9+6VepcH+0+k4dDYT5mZizBjuj9j+XjA3e/hJnZXKqjshvTwDmZVZUGnVAAAHub1eSPe0coeZ2KydHo1xtEefXCq6ii3Xd6BKVY1xPqMw0W8MJD3gU4aOxPcwIqK2YSg3AEM5NemofikoqcGm71LwS1oxPJ2s8NR4w0taHkStVSO7KlcX0tPK0lGurAAASMUS3QRS/8b/utoyf4/SJ5XKKmy7sRvnCy/B09odT4XOgY/Cq51b2DPxPYyIqG0Yyg3AUE5NOrJfBEHAzym3sem7FBRX1GFQn4aSFntF20paDLmf0voyXUi/VZ6O7Ko8aAUtAMDN0qUxpDfUp7taOpv0BNKHXRHnfOElbLuxG7XqOkz0G4vxvqO6/KcGpoTvYUREbcNQbgCGcmrSGf1Sr9LgwOkMHDybCTMzEaYP88fYAY9W0vLA+9QokXHXhY3SyjNQo64FAFiZW8Lf1kcX0n1tvE1q4mNb+6SsvhzfXN+Fy7evwlfhjadC58DD2q0DW9gz8T2MiKhtGMoNwFBOTTqzXwpLG0paLqcWw93REk+NC0Kon0On3LdW0KKw5rZeSM+vKQQAiEVieFm760J6gK0v7GV2RhtNN7RPBEHAmbxz2H5zL9RaNaYETMBor+EcHe8gfA8jImobhnIDMJRTE2P0S0NJyw3cLq/DwBAXzI3tBQebzr+ATbWqBrfKM3STSNMrMqHUqgAAdjJb3eTRAFtfeFl7wFxs3intMqRPimtLsfn6diSV3ECgrT+eCp0NF0vnTmlfT8X3MCKitmEoNwBDOTUxVr8oVRocPJuJA2cyIBaJMHWYH8YP9O7QkpYH0Wg1yKnOaxxNbwjqJXWlAACJ2Bw+Cm9dSPe39YVC2vIbzaO6X59oBS1O5pzBrtQDEAA8HjgJwz0HQywy3vPWU/A9jIiobRjKDcBQTk2M3S9FZbXY/F0Kfr55G24OllgwLghh/p1T0mKIsvpyvZCeVZkDjaABALhYON01mu4HNyuXdgnHrfVJYc1tbEzehptltxBi3xvzQ2bB0cJ0nqvuztivFSKiroah3AAM5dTEVPrlcuptbDqSgsKyWvQPdsa82N5wtO38kpYHUWpUyKzMRlpjXfqt8gxUqaoBABbmcvjZ+CDQ1g/+tr7ws/GG3Lztj+HePtEKWhzN+gH70g7DXGyGmb2mYoj7AJNeQaY7MpXXChFRV8FQbgCGcmpiSv2iUmtw6Gwm9p/OAETAlCF+mBDjA4m56ZZmCIKAotrbdy3HmIG86gIIECCCCJ7W7ndd3MgPjnL7B4bpu/sktyofG5PjkV6Rib5OoZgXPLNbXsW0KzCl1woRUVfAUG4AhnJqYor9cru8FlsSbuLCjSK42ltg/rgg9A1wNHazDFajqkV6RaYupN+qyEC9RgkAsJEq9EK6t8ITksYJpIn5F7An9RDK6stgJ7ODr8IbV4qvQWYuwxO9p6O/az+OjhuRKb5WiIhMGUO5ARjKqYkp98uVtGJsPHIDBaW1iA5yxrwxveBka2HsZrWZVtAitypf7+JGt+tKAADmIjP42HhBbibHjdKbUDfWqzfxU3jjxchnOmxSKRnOlF8rRESmyGRDuVKpxPvvv4/du3ejoqICISEhWLZsGYYMGXLf42JjY5GTk9Pibb6+vjh8+HCb28JQTk1MvV9Uai0O/5SJvafSAQGYPMQXcYN8IDHv2mtxl9dX4lZFBtLK03WTSFtiL7PD34f9uZNbRy0x9dcKEZGpuV8o75xFhluxYsUKHD58GIsWLYKvry927tyJpUuX4uuvv0ZUVFSrx/35z39GdXW13rbc3FysXbsWw4YN6+hmExmVxFyMyUP8MLiPG745moKdP9zCj7/k48mxvRHZy8nYzXtotjIF+jmHo59zOADg5aN/anG/0vqyzmwWERFRpzBaKL98+TL279+PlStXYvHixQCAGTNmYMqUKVizZg02btzY6rFjx45ttu3jjz8GAEydOrVD2ktkahxt5fjV431x9VYJNh65gffjL6NfLyc8ObY3nO26XknLvexldi0GcHuZnRFaQ0RE1LGMtoTDoUOHIJFIMGfOHN02mUyG2bNn4/z58ygsLGzT+fbt2wcvLy9ER0e3d1OJTFqYvwPeeDYGc0YFIimjFKs+O4vdJ29BqdI8+GATNi0wDhKxRG+bRCzBtMA4I7WIiIio4xgtlCclJcHf3x9WVlZ62yMiIiAIApKSkgw+17Vr15CamoopU6a0dzOJugRzMzEmDvbFW0sHoV8vJ+w+eQurPjuLn1NuG7tpDy3GLRrzQ2bBXmYHERpGyOeHzEKMG//wJiKi7sdo5StFRUVwdXVttt3Z2RkA2jRSvnfvXgDAtGnT2qdxRF2Ug40cL80Ix8j0hpKWD7ZfRkSgI+aP7Q0Xe0tjN6/NYtyiEeMWzQmFRETU7RktlNfV1UEikTTbLpPJAAD19fUGnUer1WL//v3o06cPAgMDH7o9rc2E7WjOzgqj3C/dX1fvl5HOCgyN8sbeH9Kw5UgyXlufiJmje2F2bG/IpUad3/3QunqfdFfsFyKi9mG0385yuRwqlarZ9qYw3hTOHyQxMREFBQW6yaIPi0siUpPu1C+Phbsi3NcOW4/dxDdHbuC7s5l4cmxvRPV26lIX3elOfdKdsF+IiNrmfksiGq2m3NnZucUSlaKiIgCAi4uLQefZu3cvxGIxJk+e3K7tI+ou7BUyvDAtDH96MgpyqRk+2vEL3tt2CQUlNcZuGhERETUyWigPCQnBrVu3mq03funSJd3tD6JUKnH48GHExMS0WJ9ORHeE+Nrjr88MxLzYXriZXY7X1p/F9hOpqFd27VVaiIiIugOjhfK4uDioVCps27ZNt02pVGLHjh2Ijo7Whezc3Fykpqa2eI4TJ06goqKCa5MTGcjcTIzxMT54+/nBGBjigv2nM7DqszM4l1wII17cl4iIqMczWk15ZGQk4uLisGbNGhQVFcHHxwc7d+5Ebm4u3nnnHd1+y5cvR2JiIq5fv97sHHv37oVUKsWECRM6s+lEXZ6dtQxLp4ZhZD9PbDh8HR/vuoIwP3vMHxcEd0erB5+AiIiI2pXRRsoBYPXq1Vi4cCF2796Nv//971Cr1fjkk0/Qv3//Bx5bVVWF48ePY9SoUVAoOPuf6GEEedvhr88MxJNjeyMtrwJ/WZ+Ibcdvok6pNnbTiIiIehSRwM+sAXD1Fbqjp/ZLebUS8cdu4scr+bBXyDBvTG8MCHY2iVVaemqfmDr2CxFR25jk6itEZFpsraR4dkofrHwqGgoLCdbtuoI1W35G7u3qBx9MREREj4ShnIj09Payw2uLB2DBuCCk51fir/9LxNajN1Fbz5IWIiKijtI1L+1HRB3KTCzGmP5eGBjigvgTqTiUmIkz1/IxN7Y3YkJdTKKkhYiIqDvhSDkRtcrGSoolk0Lx6sL+sLWS4b97ruKfmy8ip6jK2E0jIiLqVhjKieiBAj1t8drTA7BwfBCyCqvwt89/wpaEFJa0EBERtROWrxCRQcRiEUZHe2FAiAu2n0jFkZ+ycDapAE+M7oXBfVxZ0kJERPQIOFJORG2isJRi8cRQvLpoAOytZfh07zX8Y9NFZBeypIWIiOhhMZQT0UMJ8LDBqkUDsCguGDlFDSUtm767gZo6lrQQERG1FctXiOihicUijOrniQHBLthxIhUJ57KRmFSIOaMCMTTcjSUtREREBuJIORE9MmsLCRbFhWDV0wPgaCPH+v1JeGfjBWQW8GqPREREhmAoJ6J24+9ug1cX9cfiiSHIL67B61/8hI1HbqCmTmXsphEREZk0lq8QUbsSi0QYEemB6CBn7PwhDUfPZyMxqQCzRwViWF93iFnSQkRE1Ey7jJSr1Wp8++232Lp1K4qKitrjlETUxVlbSLBwfDD+snggXOwt8PmBZLyz4Twy8lnSQkREdC+RIAhCWw5YvXo1zp49i+3btwMABEHAokWLcO7cOQiCADs7O2zduhU+Pj4d0uCOUlxcBa22TU/FI3N2VqCosIBHbwAAIABJREFUiAHF1LBf2p9WEHDql3xsO34TVbUqjIryxMwRAbCSSww6nn1imtgvRERtIxaL4Oho3fJtbT3ZDz/8gAEDBuh+Pnr0KH766Sc8++yzePfddwEAn3zyyUM2lYi6I7FIhOER7njn+cGIjfbC8Ys5WPnfM/j+Ui60bRsXICIi6pbaXFOen58PX19f3c/Hjh2Dl5cXXnnlFQBASkoK9u7d234tJKJuw1IuwYJxQXgswh0bjtzAFweT8f2lXCwYFwR/dxtjN4+IiMho2jxSrlKpYG5+J8ufPXsWQ4cO1f3s7e3NunIiui8fVwVWLojGs5NDcbu8Dn//8hy+OpSMqlqu0kJERD1Tm0O5m5sbLl68CKBhVDwrKwsDBw7U3V5cXAxLS8v2ayERdUsikQjD+rrj7aWDMWaAF76/lIeV/z2N4z/ndPr8DiIiImNrc/nK5MmT8fHHH6OkpAQpKSmwtrbGyJEjdbcnJSV1uUmeRGQ8lnJzzB8bhBERHthw+Dq+OnQd3/+ci6fGB6OgtAY7TqSipKIeDjYyzBwZiCFhbsZuMhERUbtrcyh/4YUXkJeXh4SEBFhbW+Mf//gHbGwaakErKytx9OhRLF68uL3bSUTdnJeLNZYviMaZawXYevQm/v7VOYhFQNOgeXFFPb48mAwADOZERNTttHlJxPvRarWorq6GXC6HRGLYUmemgksiUhP2i/HV1qvxh3//iDqlptltjjYy/PNXw4zQKroXXytERG1zvyUR2/WKnmq1GgqFoj1PSUQ9kIXMvMVADjSMmBMREXU3bZ7oeeLECXz44Yd62zZu3Ijo6Gj069cPf/jDH6BScQUFIno0jjayFrfLpWaorVd3cmuIiIg6VptD+fr165GWlqb7OTU1FW+//TZcXFwwdOhQHDhwABs3bmzXRhJRzzNzZCCk5vpvUWKRCHVKDf786RkkJhWgHavviIiIjKrNoTwtLQ3h4eG6nw8cOACZTIb4+Hh89tlnmDRpEnbt2tWujSSinmdImBuenhgCRxsZRGgYOX92SihWLRoAWysp/rP7Kt7begmFpTXGbioREdEja3NNeXl5Oezt7XU/nzp1CoMHD4a1dUPRekxMDE6cONF+LSSiHmtImBuGhLk1m1D42tMDcPRCDnZ+n4ZVnyViylBfTBzkC4l5m8cZiIiITEKbf4PZ29sjNzcXAFBVVYVf/n97dx4XZbm3AfyagZlhHfZNNgERFJFVDc1dFM0tcyn3Fsu1zLdOWafN8tRJU8tMSzu5RJkLiLu4lbmUCyouLIqoIKso+zYw8/6BTI4ggg48A1zfz+d83neeeZbfcENe3NzP77lwAcHBwer3KyoqUFlZ+w1aRETaoCcWIzTYGQunPYUAT2ts+zMZH/7vJOKu3xG6NCIiosfS4Jlyf39/bNy4Ee3atcORI0dQWVmJXr16qd+/ceMGbG1ttVokEVFtLExlmDGyE3pey8HP0YlYtPEcnvKxw7h+njAzlgpdHhERUb01eKb89ddfh1KpxNy5cxEREYGRI0eiXbt2AACVSoUDBw4gMDBQ64USET1MJ3crLHi5K4Z1b4vT8Vl474e/cDgmtcmfPUBERPS4HuvhQbm5uYiJiYGpqSm6dOmi3p6Xl4dt27ahW7du8Pb21mqhjY0PD6JqHBfd05AxSc8pws/RiYi7cRduDqaYPMgbrvZ8fkJj4M8KEVHD1PXwIK0+0bM5YyinahwX3dPQMVGpVPj7ciY2HryCghIF+gc64dle7jCUafV5aa0ef1aIiBqmUZ7oefPmTRw8eBApKSkAAGdnZ/Tv3x8uLi6Pe0oiIq0QiUR4yscenT2ssPXINRw8k4pTCVl4ob8nunjbQiQSCV0iERGRhseaKV+2bBlWr15do8uKWCzGa6+9hjfeeENrBTYVzpRTNY6L7nnSMbmWlo/1++JxM7MQPm6WmDiwPewsjLRYYevEnxUioobR6kz5li1bsGrVKgQEBOCVV16Bp6cnAODKlSv48ccfsWrVKjg7O2PUqFFPVjURkZa4t5Fr9Db/YM1JDA1xxeCn2NuciIh0Q4NnykeNGgWJRILw8HDo62tm+oqKCkyYMAEKhQIRERFaLbSxcaacqnFcdI82x+RuQRk2HryCU/FZsLM0wqSB7dGxraVWzt3a8GeFiKhh6popb/AUUVJSEoYMGVIjkAOAvr4+hgwZgqSkpIZXSUTUBKp7m88b6weVUoXFG8/hh+2XkFdYJnRpRETUijU4lEskEhQXFz/0/aKiIkgkkicqioiosWn0Nk/Iwnur/8Yh9jYnIiKBNDiU+/r64rfffsPt27drvJeTk4NNmzbBz89PK8URETUmqUQPz/ZyxycvdUVbe1P8HJ2IhRtO40YGl2QQEVHTavCa8lOnTmHq1KkwNjbGc889p36a59WrVxEREYGioiKsXbsWwcHBjVJwY+GacqrGcdE9TTEm7G3ecPxZISJqGK0/POjQoUP49NNPkZ6errG9TZs2+PDDD9GnT5/HKlRIDOVUjeOie5pyTIpLFdh65Bp+j7kFuYmUvc3rwJ8VIqKGaZQneiqVSly8eBGpqakAqh4e5OPjg02bNmH9+vXYvXv341csAIZyqsZx0T1CjAl7mz8af1aIiBqmUZ7oKRaL0blzZ3Tu3Flj+927d5GcnPy4pyUi0gnsbU5ERE2JiyWJiB5CTyxGaLAzgr1ssfHgFWw7mowTlzPZ25yIiLSO0z1ERI+g7m0+jr3NiYiocTCUExHVUye3qt7mw3uwtzkREWmXoKG8vLwcixYtwtNPP43OnTtj7NixOHHiRL2P37FjB0aPHg1/f3907doVEydORGxsbCNWTEStnVSih5E93bHg5W4avc2vZ+QLXRoRETVj9VpT/tNPP9X7hDExMfXe991330V0dDQmT54MV1dXREZGYtq0adiwYQMCAgLqPHbp0qVYs2YNhg8fjnHjxqG4uBjx8fHIzs6u9/WJiB6XvaUR3nrev6q3+aGr+HTdafQLdMKzPd1hZMDbdYiIqGHq1RLR29u7YScViRAXF1fnPrGxsRgzZgzmz5+PqVOnAgDKysowdOhQ2NraIjw8/KHHxsTEYPz48Vi+fDlCQ0MbVNvDsCUiVeO46B5dH5PW2ttc18eFiEjXPHFLxPXr12u1IADYu3cvJBIJxowZo94mk8kwevRoLF26FFlZWbC1tX1oPb6+vggNDYVSqURJSQmMjY21XiMRUX0YGUgwaaAXnvZ1wPq9CVgVdQl/xqaztzkREdVbvUJ5165dtX7huLg4uLm51QjTnTt3hkqlQlxc3END+YkTJ/DMM89gyZIl2LBhA4qLi+Ho6Ii5c+di+PDhWq+ViKg+3Byqe5unIoK9zYmIqAEEW/iYnZ0NOzu7GtttbGwAAFlZWbUel5eXh9zcXOzatQt6enp46623YG5ujvDwcLz99tswNDTU2pIWIqKGEotFGBDsjCAvW/x26F5v80sZmDjICz7sbU5ERA8hWCgvLS2FRCKpsV0mkwGoWl9em+LiYgBAbm4uNm3aBD8/PwBAaGgoQkNDsWLFiscK5Q9b39PYbGxMBbku1Y3jonua25jY2JjiA3drxCRkYdXWWHy18Rx6BTjileGdYCE3ELo8rWlu40JEpKsEC+UGBgZQKBQ1tleH8epw/qDq7U5OTupADgBSqRSDBg3C+vXrUVRU1OA15rzRk6pxXHRPcx4TZ0tDfDQ1GLv/uoHdf93AqcuZGNXLHX0DHCEWN+8bQZvzuBARCaGuGz0FW+RoY2NT6xKV6paGD1tPbm5uDqlUCmtr6xrvWVtbQ6VSobCwULvFEhE9gQd7m4fvT8Rn69nbnIiI/iFYKPf29kZycjKKioo0tp8/f179fm3EYjE6dOiAzMzMGu9lZGRAT08PZmZm2i+YiOgJVfc2f3VYR9wpKMOn604jfH8iiksrhC6NiIgEJlgoDwsLg0KhwObNm9XbysvLERERgcDAQPVNoGlpaUhKSqpxbHp6Oo4dO6beVlhYiD179iAgIAAGBi1nvSYRtSwikQhP+djjP9O6oU+AIw6dScX7a/7CybhM1OOxEURE1ELV6+FBjeWNN97AwYMHMWXKFLi4uCAyMhIXL17EunXrEBQUBACYNGkSTp48iYSEBPVxJSUlGDVqFDIzMzF16lTI5XJs3boVycnJGsc2BNeUUzWOi+5pyWOSnJ6P9XsTcCOzAD5uls2qt3lLHhciosZQ15pyQUN5WVkZli1bhh07diAvLw9eXl6YN28eunfvrt6ntlAOVK09//LLL/HHH3+gtLQUPj4+mDdvHrp06fJYtTCUUzWOi+5p6WOiVKrUvc0rKlXNprd5Sx8XIiJt09lQrksYyqkax0X3tJYxuVtQht8OXcHJuCzYWRjqfG/z1jIuRETaopPdV4iISJOFqQzTR3TCvHF+UKmArzaew/fbLyGvsPbnNhARUcvBUE5EpGM6uVnh01e6YniPtjiTkIX3Vv+Ng2dSm/yveURE1HQYyomIdJBE/5/e5m4O7G1ORNTSMZQTEekwe0sj/N84f7w6nL3NiYhaMn2hCyAiorqJRCI81dEend2tEHHkGg6dScXp+Cy8MMATXbxtIRKJhC6RiIieEGfKiYiaCSMDCSYO9MK/pwTD3ESGVVGXsOS3c8i8Uyx0aURE9IQYyomImhk3Bzk+mBKM8QM8kZSWjw9+PImoo8lQVFQKXRoRET0mLl8hImqGxGIRBgQ7I8jLFr8duoKoo8n461KGzvc2JyKi2nGmnIioGWNvcyKiloEz5URELUB1b/NdJ25g9183EJt0G6N6eaBvgCPEYt4I2tKduJSBiD+SkJNfBiu5DKN6eyDEx17osoioAThTTkTUQmj2Npezt3krceJSBtbtiUdOftVfR3Lyy7BuTzxOXMoQuDIiagiGciKiFqbW3ubR7G3ekiiVKuTklSLh5l38ciAR5RVKjffLK5SI+CNJoOqI6HFw+QoRUQtUo7d5TCpOJ7C3eXOhVKqQW1iG23mluJ1Xcu//liInrxTZuSW4W1CGSqWqznNUz5wTUfPAUE5E1IJV9zbv4euA9XsTsCrqEv48n4aJA71gZ2kkdHmt1v2hOyevFNn3gnfOvRB+J79m6DYzkcLazAAejmawNjO49z9D/LjrMnILy2tcw9RI0lQfh4i0QKRSqer+VbuVyMkphPIRsw7aZmNjiuzsgia9Jj0ax0X3cEy0Q6lU4VBMKiKOXENFpQrPhLhiyFMukOjrPdb5OC4P92DofnC2Oye/9KGh29rMENZmBrC6L3hbyWUPHafqNeX3L2ERAVABGNnTDUO7t4WYfxkh0glisQhWVia1vseZciKiVoK9zbVHqVIhr7D8gbCtGbxrhG7jqtDd1sEUwd626tluKzMDWMkNIJU83i9H1V1W7u++MvxpN8TfuIttfybjRkYBXhnaEYYy/pNPpMs4U34PZ8qpGsdF93BMGsfF5Bz8vC8RWbkl6NbRDs/3awczE1m9j2/J41IdujVnuf8J3XfyS1FRqflvhtxYqhG0q2e8rZ8wdD8ulUqFA2dS8dvBq7CzNMTsUb5wsDJu0hqISFNdM+UM5fcwlFM1jovu4Zg0HkVFpbq3uURf3KDe5s15XJQqFfKLynE798GlJffWdtcWuo0ksKoO2uaaodtSbgBZE4fu+oq/cRcroy5CUaHEtKEdEdDeRuiSiFothvJ6YCinahwX3cMxaXwZd4rxc3QCLl+/i7b2ppgc5oW29vI6j9HlcVGH7nsz3Dn3Qvf9y0sqKjXbCGqEbvWM9z/ru3U1dNfHnfxSfBtxAdczCjCse1uM6OnGdeZEAmAorweGcqrGcdE9HJOmoVKpcDIuCxsPXkF+cTn6BTjh2V7uMDKofS2ykOOi0gjdmsE7+yGh29RIohG0NYK33AAyafMN3fWhqKjE+n0JOHYhA509rPDqsI4wMmCHFqKmxFBeDwzlVI3jons4Jk2ruLQCkfd6m8uNpXi+vye6dqjZ27wxx0WlUiG/WFG1tCS35mx3Tn4pFA88MMfEUKLRKlDdvcS8dYTu+lCpVDh89hZ+PXAF1mYGmD3KF442tQcEItI+hvJ6YCinahwX3cMxEUZyej7W70vAjYwCdGxrgUkP9DZ/knG5P3RrLi3553Vtobs6aNvcH7rvLS8xkLK7SH0lpuTiu20XUVZeiZef6YBgb1uhSyJqFRjK64GhnKpxXHQPx0Q4SmXVzGrEkSQoKqp6m1vJZYg6mow7+WWwlMswqreHui1fNZVKhYJixUPWdFe9fvDR8PeH7gdnu63kBmzpp2V3C8qwIvICrqXl45kQVzzb071eN/gS0eNjKK8HhnKqxnHRPRwT4eUWlmHjwSs4GZdV4z19PREC29vA2EBSZ+g2NtCv9cE41a8ZupueokKJ8P2JOHI+DZ3cLPHqcB+YGHKdOVFjYSivB4ZyqsZx0T0cE93xxjd/oqBYUet7xgb6Gv25H1xqwtCtu34/dwvh0YmwlMswe1RnONtynTlRY+ATPYmISCseFsgBYPncXk1YCWlTH39HONmYYEXkBSzccBovDu6Abh3thC6LqFURC10AERE1H1by2p/4+bDt1Hy0czTDR1O7wMXOFN9vv4RNh66iUql89IFEpBUM5UREVG+jentAqq/5T4dUX4xRvT0Eqoi0ydxEhn+9EIC+gY7Ye/Imlvx2HgXF5UKXRdQqMJQTEVG9hfjYY8pgb1jJZRChaoZ8ymDvGt1XqPnS1xNj0kAvvDjEG1dS87Bg7WncyOA9HUSNjTd63sMbPakax0X3cEx0E8el5UtOz8e3ERdQWKLA1DBvhHTiL19ET6KuGz05U05ERES1cnOQ46OpXeDuIMfqnZfx64ErqKjkOnOixsBQTkRERA8lN5bi/573x4BgJ+w/nYKvNp5DfhHXmRNpG0M5ERER1UlfT4zxA9rjlaEdcC09H5+sPYXk9HyhyyJqURjKiYiIqF66d3LAexODIBYBn/8cg6Ox6UKXRNRiMJQTERFRvbnam+LDqV3g6WSG/+2Ow8/RCVxnTqQFDOVERETUIKZGUswb54dBXZ1xKOYWFv16FnmFZUKXRdSsMZQTERFRg+mJxRjXzxOvDffBjYwCfLL2FJJu5QldFlGzxVBOREREj61bRzu8NykI+npi/PeXGBw5nyZ0SUTNEkM5ERERPREXu6p15l4uFli7Jx7r9sZDUcF15kQNwVBORERET8zEUII3x/hhyFOu+ONcGr78JQZ3C7jOnKi+GMqJiIhIK8RiEUb38cDMkZ2Qml2EBWtP4UpqrtBlETULDOVERESkVcHetnh/chBkUj18+ctZHI5JhUqlErosIp3GUE5ERERa52Rjgg+nBMPHzRIbohPx0554KCoqhS6LSGcxlBMREVGjMDKQ4PXRnTGse1scjU3HF+ExuJNfKnRZRDqJoZyIiIgajVgkwrO93DF7lC/Sc4rxydpTSLh5V+iyiHQOQzkRERE1usD2Nvj35GAYG0iw6Ndz2H86hevMie4jaCgvLy/HokWL8PTTT6Nz584YO3YsTpw48cjjli9fDi8vrxr/69GjRxNUTURERI+jjbUx/j05GJ09rPDrgStYszMO5QquMycCAH0hL/7uu+8iOjoakydPhqurKyIjIzFt2jRs2LABAQEBjzx+wYIFMDAwUL++//8nIiIi3WNkoI/Zz/li57Hr2HY0GbduF2L2KF9YmxkKXRqRoAQL5bGxsdi1axfmz5+PqVOnAgBGjhyJoUOHYvHixQgPD3/kOQYPHgy5XN7IlRIREZE2iUUiDH/aDS72pli94xIWrD2NGSN80KGtpdClEQlGsOUre/fuhUQiwZgxY9TbZDIZRo8ejTNnziArK+uR51CpVCgsLOSaNCIiombIv501PpjSBXJjKRb/dg57/77Jf9Op1RIslMfFxcHNzQ3GxsYa2zt37gyVSoW4uLhHnqNPnz4ICgpCUFAQ5s+fj9xcPjWMiIioObG3NML7k4IQ6GmDTYev4ocdl1HGdebUCgm2fCU7Oxt2dnY1ttvY2ABAnTPlcrkckyZNgp+fHyQSCf766y/89ttvuHz5MjZv3gypVNpodRMREZF2Gcr0MfPZTtj91w1E/HENt7KLMPs5X9iac505tR6ChfLS0lJIJJIa22UyGQCgrKzsocdOmTJF43VYWBg8PT2xYMECbNu2DWPHjm1wPVZWJg0+RhtsbEwFuS7VjeOiezgmuonjQto0dbgvfNvbYtHPZ/DZutN4e1IwAr1shS6LqEkIFsoNDAygUChqbK8O49XhvL5eeOEFLFq0CCdOnHisUJ6TUwilsmnXsdnYmCI7u6BJr0mPxnHRPRwT3cRxocbgYmWEDyYH4duIC/h49Qk819sDg7u5QCQSCV0a0RMTi0UPnQgWbE25jY1NrUtUsrOzAQC2tg37zVgsFsPOzg55eXlaqY+IiIiEYWthhPcnBaOLty22/J6EldsuorS8QuiyiBqVYKHc29sbycnJKCoq0th+/vx59fsNoVAokJ6eDgsLC63VSERERMKQSfXw2nAfjO3bDmcSs7Fw/Rlk3i0WuiyiRiNYKA8LC4NCocDmzZvV28rLyxEREYHAwED1TaBpaWlISkrSOPbOnTs1zvfjjz+irKwMPXv2bNzCiYiIqEmIRCKEdXPBvHH+yC0sw4K1pxGbdFvosogahWBryv38/BAWFobFixcjOzsbLi4uiIyMRFpaGj7//HP1fu+88w5OnjyJhIQE9ba+fftiyJAhaN++PaRSKf7++2/s27cPQUFBGDp0qBAfh4iIiBqJT1tLfDS1C76NuICvN8diZE83PNO9LcRcZ04tiGChHAC+/PJLLFu2DFFRUcjLy4OXlxd++OEHBAUF1XncsGHDEBMTg71790KhUMDR0REzZ87Ea6+9Bn19QT8SERERNQJrc0PMnxSEdXvjEflnMq5nFOCVoR1hKOO/+9QyiFR8dBYAdl+hf3BcdA/HRDdxXEgIKpUK+0+nYtOhq7CzNMTsUb5wsDJ+9IFEOkAnu68QERERNZRIJMLALs5463l/FBQr8Om60zh7JVvosoieGEM5ERERNTverhb4aGoX2FkaYfnWC9j25zUo+cd/asYYyomIiKhZsjIzwPwJgejRyR7bj13H8i2xKC5lP3NqnhjKiYiIqNmSSvTw0jMdMCG0PS4m38Gn607h1u2iRx9IpGMYyomIiKhZE4lE6B/khLdfCEBJWQU+W38aZxJqPjWcSJcxlBMREVGL0N7ZHB+92BWO1sZYEXkRW/9IavLOakSPi6GciIiIWgwLUxneGR+IXn4O2HXiBpZtOY+iUoXQZRE9EvuU3/OoPuUKRTkKCnJRUVEOpbJSK9cUi8VQKpVaORdpz5OMi56ePkxMzGFoyJ652sR+2LqJ40K67vdztxAenQhLuQxzRnWGk23t/aGJmkpdfcoZyu+pK5SXlBShoOAuTEzMIJMZQizWg0gLj/bV1xejooKhXNc87rioVCooFOXIzc2GqakFg7kWMfzpJo4LNQdXb+VhReQFlJRV4KUhHdC1g53QJVErxocHPaHCwjyYm1vDyMgUenr6Wgnk1PKIRCJIpTKYm9ugsDBX6HKIiAhAO0czfDS1C1xsTbEq6hI2Hb6KSv6VmnQQQ3k9VFYqIJHIhC6DmgmJRIrKSvbJJSLSFeYmMvxrfAD6Bjhi7983sXTTeRSWcJ056RaG8nri7DjVF79XiIh0j76eGJMGeWHqYG8kpuRiwdpTuJnJ5VekOxjKiYiIqNXo5dcG704IQqVShf9sOIMTlzKELokIAEM5NbLZs1/F7NmvNvmxRERED+PeRo4Pp3ZBWwc5Vu+4jF8PXOE6cxKcvtAFkDCefjq4Xvtt3rwdDg5tGrkaIiKipmVmLMVbz/tj06Gr2H86BSlZBZg+shPkRlKhS6NWii0R76mrJWJGxg3Y27tq/ZpCtkTct2+3xutNm35FZmY65syZp7G9V6++MDQ0fOzrKBRVN9JIJJImPfZJaGNcGut7prVi6z3dxHGhluLYhXSs35cAUyMJZo/yRVt7udAlUQtVV0tEzpS3UoMGDdF4/fvvB5GXl1tj+4NKS0thYGBQ7+s8SaBu6jBOREStUw9fBzjaGGNFxAX8Z0MMpoR5oYevg9BlUSvDNeX0ULNnv4qpU8fj8uWLmDHjZfTr1wPh4esAAH/++TvefvsNjBgRhr59QzB27AisXbsGlZWVNc5x/7rwmJjTePrpYPzxxyGsXbsGI0cORr9+3fHGGzOQmpqitWMBYOvWTRgzZgT69euBadMm4/z5s1ynTkREtWprL8cHU7vA08kMP+6KQ3h0Iioquc6cmg5nygVy4lIGIo5cQ05eKazkMozq7YEQH3uhy6ohN/cu/vWvNzFwYBjCwp6BnV1Vjbt374ShoRHGjZsAIyNDnDlzGmvWrEJRURFmzXrjkeddt+5HiMV6GD9+MgoK8vHrrxvwySf/xurV67RybGTkFixd+iX8/QMxbtwLSE9Px/z5b8HU1BQ2NraP/wUhIqIWS24kxbxxftjyexL2naxaZz7jWV+YGXOdOTU+hnIBnLiUgXV74lF+b91yTn4Z1u2JBwCdC+a3b2fj3Xc/wNChIzS2f/zxZ5DJ/lnGMnLkaCxa9B9ERm7GtGkzIJXW/R+wiooK/O9/66CvX/UtKJeb4euvF+Patatwd2/3RMcqFAqsWbMSPj6+WLbsO/V+7dp5YuHCjxnKiYjoofTEYozr5wlXe1Os3R2PBWtPYeazneDRxkzo0qiFYyh/AscupONobHqDj0tKy0NFpeZNpeUVSvy0Ow5HzqU1+HxPd3ZotLVvBgYGCAt7psb2+wN5cXERyssV8PMLQFRUBG7cuA5Pz/Z1nveZZ4arwzIA+Pn5AwDS0m49MpQ/6tj4+MvIy8vDzJnPauwXGhqGb75ZUue5iYiIAOCpjvaWD8HkAAAeQ0lEQVRoY2WMbyMu4L/hMZg40Au9/NiNjBoPQ7kAHgzkj9ouJBsbW41gW+3atSSsXr0SMTGnUFRUpPFeUVHhI89bvQymmqlp1Z3uBQWP7uTwqGMzMqp+UXJyctbYT19fHw4OvHGHiIjqx8XOFB9O7YLvoy5i7Z54XE/PxwsD2kOiz1vySPsYyp9AD9/Hm6F++7tjyMkvq7HdSi7DOxMCtVGa1tw/I16toKAAc+a8CiMjE7z88nQ4OjpBKpUiMTEeK1cuh7IeD2AQi/Vq3V6fDp1PciwREVFDmBhK8OZYf2w9koQ9f91ESnYhZo70hYWpTOjSqIXhr3oCGNXbA9IHfsuW6osxqreHQBU1zNmzZ5CXl4f33/8IY8e+gB49eqJLl27qGWuh2dtX/aL0YEeWiooKpKc3fLkRERG1bmKxCGP6tMOMkZ2QmlWEBWtP4UpqrtBlUQvDUC6AEB97TBnsDSuzqlloK7kMUwZ769xNng8jFld929w/M61QKBAZuVmokjR4e3eEmZkZtm+PREVFhXr7/v17UVCQL2BlRETUnHXxtsX7k4Mgk+jhy1/O4vDZW/wrLWkNl68IJMTHHj392gj2RM8n4evbGaamcixc+DFGjx4HkUiEfft2Q1f+uySRSPDSS69i6dJFmDt3Jvr27Y/09HTs2bMDjo5OEIlEQpdIRETNlJONCT6YGowftl/Ghn0JSE7Px6SB7SHRr31pJVF9caacGszMzBxffrkUVlbWWL16JX799WcEB3fDzJmvC12a2nPPjcPcuW8hIyMdK1Z8jfPnz+KLL5bAxMQUUinXARIR0eMzNpDgjdGdMbR7WxyNTccX4TG4k18qdFnUzIlU/LsLACAnpxBKZe1fioyMG7C3d9X6NfX1xc1ypry5UiqVGDo0FL1798U77/z7oftpY1wa63umtbKxMUV29qM781DT4rgQAWcSsrFm12XI9MWYMbITvFwshC6JdJhYLIKVlUnt7zVxLURNoqysZnebvXt3IT8/DwEBQQJURERELVGQlw0+mBwMQwMJFm88hwOnU7jOnB4L15RTixQbew4rVy5Hnz79IJebITExHrt2bYe7uwf69h0gdHlERNSCtLE2xgeTg7Fm52X8cuAKrmcUYPIgL0glXGdO9cdQTi1SmzaOsLa2wZYtvyE/Pw9yuRnCwp7B9OmzIZFIhC6PiIhaGCMDfcx+zhc7j13HtqPJuJVdhJBOdth/KgU5+WWwksswqrdHs+m0Rk2Pa8rv4ZpyqsY15bqHa5d1E8eFqHbnrtzGym0XoHjgSd1SfXGzaoFM2sc15URERERNxN/TGsaGNf8qW16hxNY/kgSoiJoDLl8hIiIi0rLcwvJat9/JL8N/w2PQ3tkc7V3M0a6NGWRSrj0nhnIiIiIirbOSy5CTX7MTmIFUD6WKSuw8cR2q44CeWARXe9OqkO5sjvZOZjAy4L1PrRFDOREREZGWjertgXV74lF+3z1KUn0xJg3yQoiPPUrKKnD1Vh4SU3KRkJKL/adSsPfvmxABcLY1+SekO5tDbiwV7oNQk2EoJyIiItKy6ps5I/5IqrX7iqFMH77uVvB1twIAlCsqcS0tXx3Sj5xPw4EzqQAABysjtHc2h9e9kG4pNxDmQ1GjYignIiIiagQhPvb17rQilejB29UC3q5VTwStqFTiekYBElNykZiSi5NxmfjjXBoAwNrMQB3Q27uYw9bcECKRqNE+BzUNhnIiIiIiHaOvJ0Y7RzO0czTDkKdcoVSqkJJViIR7If18Ug6OXcwAAJiZSOF130y6g7UxxAzpzQ5DOREREZGOE9+7IdTV3hQDuzhDqVIhPadYPZOecPMuTsZlAQBMDCXwdDKrCuku5nCxNYVYzJCu6xjKSSt2796B//znE2zevB0ODm0AAKNHD0NAQBDef//jBh/7pGJiTuP116fjm29WITAwWCvnJCIi0hVikQiO1sZwtDZG3wBHqFQqZOeWqGfSE1NycfbKbQBVHV88nczR3tkMXs4WaOtgCn09PqpG1zCUt1L/+tebiIk5hR079sPQ0LDWfebNm41Lly5g+/ZoyGSyJq6wfg4c2Ic7d3Iwdux4oUshIiISjEgkgq2FEWwtjNCzc9UE1538UiSm5iIxJQ8JN+/iwrUcAFVdYNzbyKtuHnWxgHsbOWQS9koXGkN5KxUaOgjHj/+Jo0f/QGhoWI337969gzNnTmHgwMGPHch/+WUrxOLG/U384MFoXLmSWCOU+/sH4uDBY5BI2OuViIhaJ0u5AZ7qaI+nOlbdbJpfVI4rqbnq2fQdx65j+7Hr0BOL4OYgV7dg9HQyg6GMEbGp8SveSvXs2QeGhkY4cGBfraH80KEDqKysxMCBNd+rL6lUuL6qYrFYZ2f3iYiIhCA3liLIyxZBXrYAgOJSBa7eyqsK6Tdzse/kTez+6wZEIsDF1hReLv+EdFMj9kpvbAzlrZSBgQF69uyNw4cPID8/H3K5XOP9Awf2wcrKCs7Orli8+AucOXMSmZmZMDAwQGBgMGbNeuOR679rW1N+7VoSli1bhIsXL8DMzAwjRoyCtbVNjWP//PN3bN8eicTEBOTn58HGxhZDhgzDpEkvQk+v6k9ss2e/inPnYgAATz9dtW7c3t4BW7bseOia8oMHo/Hzz2tx48Z1GBkZo0ePnpgx43WYm5ur95kxYxoKCgrw4YcLsGTJl4iLuwRTUznGjHkeEyZMadgXmoiISEcZGUjQ2cManT2sAQBl5ZVISstTr0k/fPYWok+lAAAcrY01HmhkYcqJL21jKBfIyYwY7Li2F3dKc2EhM8dwjzB0tQ9s0hpCQ8MQHb0Hv/9+EMOHP6venpGRjosXYzF69POIi7uEixdjMWDAINjY2CI9PQ3btm3FnDmv4eefN8PAoP4PMMjJuY3XX58OpVKJiROnwMDAENu3R9Y6o717904YGhph3LgJMDIyxJkzp7FmzSoUFRVh1qw3AABTpryEkpISZGamY86ceQAAQ0Ojh16/+oZSHx9fzJjxOrKyMrF162+Ii7uE1avXa9SRn5+H//u/19G3b3/07z8Qhw8fwMqVy+Hu3g4hIT3q/ZmJiIiaC5lUDx3bWqJjW0sAgKJCiesZ+Ui4WRXSj1/KwOGztwAAthaGGg80sjYzYK/0JyRoKC8vL8fXX3+NqKgo5Ofnw9vbG2+++SZCQkIadJ5p06bhyJEjmDx5Mt5///1GqlZ7TmbE4Jf4rVAoFQCAu2W5+CV+KwA0aTDv0qUbzM0tcODAPo1QfuDAPqhUKoSGDoKHRzv07TtA47gePXph+vQX8fvvBxEW9ky9rxcevg55eblYs2YDvLy8AQCDBw/FCy88W2Pfjz/+DDLZP4F/5MjRWLToP4iM3Ixp02ZAKpWiS5enEBGxGXl5uRg0aEid166oqMDKlcvRrl17LF/+vXppjZeXNz7++H3s2BGJ0aOfV++flZWJjz76TL20Z+jQERg9eih27YpiKCciolZBoi+Gp5M5PJ2q/ppcqVTiZmbhP91dErNxNDYdAGBhKlO3YPRyNoe9pRFDegMJGsrfffddREdHY/LkyXB1dUVkZCSmTZuGDRs2ICAgoF7n+P3333H69OlGrrR2f6efwYn0Uw0+LjnvJipUFRrbFEoFwuO24HjayQafL8ShC7o5BDX4OH19ffTrNwDbtm3F7du3YW1d9eerAwei4eTkjI4dO2nsX1FRgaKiQjg5OcPExBSJifENCuUnThyDr6+fOpADgIWFBUJDByMycrPGvvcH8uLiIpSXK+DnF4CoqAjcuHEdnp7tG/RZ4+Mv4+7dO+pAX61fv1CsWPE1jh8/phHKTUxMMGDAIPVriUSCDh18kJZ2q0HXJSIiain0xGK4Ocjh5iDHoK4uUKpUSLtdpJ5Jj7txF39dzgQAmBpJ1EtdvJzN4WRjwl7pjyBYKI+NjcWuXbswf/58TJ06FQAwcuRIDB06FIsXL0Z4ePgjz1FeXo7PP/8cL7/8MpYvX97IFWvPg4H8UdsbU2hoGCIiNuPQoWiMHTse168n4+rVRLz44jQAQFlZKTZsWIvdu3cgOzsLKpVKfWxhYWGDrpWZmQFfX78a211cXGtsu3YtCatXr0RMzCkUFRVpvFdU1LDrAlVLcmq7llgshpOTMzIz0zW229ra1fgN39RUjqSkqw2+NhERUUskFongZGMCJxsT9A9ygkqlQtZdzV7pZxKyAQBGMn14Opmh/b2bR13t2Cv9QYKF8r1790IikWDMmDHqbTKZDKNHj8bSpUuRlZUFW1vbOs+xfv16lJaWChbKuzkEPdYM9b+P/Qd3y3JrbLeQmWNu4HRtlFZvvr5+cHBwxP79ezF27Hjs378XANTLNpYuXYTdu3dgzJgX0KmTL0xMTACI8PHH72kEdG0qKCjAnDmvwsjIBC+/PB2Ojk6QSqVITIzHypXLoVQqG+W69xOLa+/X2lifmYiIqLkTiUSwszSCnaURevlVNYPIySuteuLovZB+Puler3SJGO0czdQz6e5t5JDot+5e6YKF8ri4OLi5ucHY2Fhje+fOnaFSqRAXF1dnKM/OzsZ3332HDz/88KEPv9FVwz3CNNaUA4BELMFwj8dvP/gkBgwYiA0bfkJqagoOHoyGl1cH9Yxy9brxOXPeVO9fVlbW4FlyALCzs0dqakqN7Tdv3tB4ffbsGeTl5WHhwkXw9/9njX16elotZ63fn8Ls7R3U17r/nCqVCqmpKXBz86jXeYiIiKj+rMwMEGJmj5BOVb3S84rKceW+kB71ZzJUAPT1RHB3kKtn0j3atL5e6YJ92uzsbNjZ2dXYbmNT1R4vKyurzuOXLFkCNzc3jBgxolHqa0zVN3MK3X2l2sCBg7Fhw0/49tulSE1N0Qjgtc0Yb936GyorKxt8nZCQHti8eSMSEuLV68rv3r2L/fv3aOxX/cCh+2elFQpFjXXnAGBoaFivXxC8vTvCwsIS27ZtweDBQ9UPFTp8+CCys7MwYcLkBn8eIiIiahgzYymCvW0R7F018VpYosDV1Dz1bPruEzex8/gNiEUiuNqb3JtJt4CnsxmMDVr2AwEFC+WlpaW1Pm2xui1dWVnZQ4+NjY3Ftm3bsGHDBq3d2WtlZfLQ97KyxNDX1+66p+5OwejuFPzoHZuAp2c7eHq2x9GjRyAWizFoUJj68z79dE/s27cbpqYmcHNzx4ULsTh16iTMzMwhEonU+1XfvKGnp/m1un+fyZOnYt++PZg3bzbGjn0eBgYG2LYtAvb2Drh69Yr62IAAf8jlcixc+DHGjn0BIhGwZ89u9Tnvv0aHDh0QHb0H3367FB07+sDQ0BA9e/aG3r11atX76utLMWvW6/jss4/x+uuvITQ0DJmZGdi8eSM8PNrh2Wefe6Bu1Bjz6u+1+nwviMVi2NiYNmQY6BH49dRNHBciehI2ANxcLBF673VJWQXir9/BpWs5uHgtB4dibmHfyRSIRICrvRyd3K3g42EFHzcrWMjr35a5ORAslBsYGEChUNTYXh3GH/Y0RpVKhYULF2LgwIEIDtZeqM3JKYRSWft6YaVSiYoK7a9j1tcXN8p5H0doaBiuXElEQEAQzM2t1HXNmfN/AETYt28PysrK4evrh2XLVmDevDlQqVTq/aq/dpWVml+r+/cxN7fCN9+swtKlX2Ldup80Hh70xRefqo81Npbjv/9dim+/XYbvv18BU1M5Bg4cjODgrpg3b7bGNYYNG4X4+Djs2rUDGzeGw97eASEhPVFZqaxRT1jYUOjrSxAevg7Lly+FsbExQkPDMH36HOjpSR6oGzXGpnrmvj5jplQqkZ1d0OBxoNrZ2Jjy66mDOC5E1BicLA3hZOmEQcFOUFRU4lpavvrG0f0nb2LnsWQAgJ2lEbzu65VuZab7IV0sFj10IlikEujOtRdffBG3b9/Gjh07NLafOHECU6dOxQ8//IDevXvXOC46OhpvvPEGfvrpJzg5Oam39+/fH6NGjcKsWbNgbW3doIfaAHWH8oyMG7C3r9kh5EnpUiinf2hjXBrre6a1YvjTTRwXImpqFZVVvdITUu4i8WYuElPzUFJW1b3OSm5Qtdzl3rp0OwvDGisqTlzKQMQfScjJL4OVXIZRvT0Q4mPfZPXXFcoFmyn39vbGhg0bUFRUpHGz5/nz59Xv1yYtLQ1KpRJTptR83HlERAQiIiKwevVq9OrVq3EKJyIiIiJB6OuJ4d5GDvc2cgzu5gqlUoXU7H8eaHQpOQcnLmUAqFq/fn+v9JtZBVi/NwHl9ybecvLLsG5PPAA0aTB/GMFCeVhYGP73v/9h8+bN6j7l5eXliIiIQGBgoPom0LS0NJSUlMDDo6o7Rr9+/TRmyKvNmjULffv2xejRo+Hj49Nkn4OIiIiIhCEWi+BiZwoXO1MMCHaGSqVCxp1i9Y2jCTdzcSq+qnmICMCDayLKK5SI+COpdYdyPz8/hIWFYfHixcjOzoaLiwsiIyORlpaGzz//XL3fO++8g5MnTyIhIQEA4OLiAhcXl1rP6ezsjAEDBtT6HhERERG1bCKRCA5WxnCwMkZvf0eoVCrk5JUiISUXP+6Kq/WYnPyHNxdpSoI2gPzyyy+xbNkyREVFIS8vD15eXvjhhx8QFNTwB/IQEREREd1PJBLB2twQ1uaG2PbntVoDuJW89uYiTU2wGz11DW/0pGq80VP38IZC3cRxIaLm5MSlDKzbE69eUw4AUn0xpgz2brLlKzp5oycRERERUVOpDt5Cdl+pC0N5PalUKq09qIhaNv7xiYiISDeF+NjrTAh/kHYfU9lC6elJoFDoxk0ApPsUinLo6fH3XSIiIqo/hvJ6MDExQ27ubRQVFaCysoIzoVQrlUqF8vIy5OZmw8TEXOhyiIiIqBnhdF49GBoaQ19fgsLCXBQV5UGprNTKecViMZRK3uipa55kXPT09GFqagFDQ+NH70xERER0D0N5PUkkUlhY2Gr1nOxcoJs4LkRERNTUuHyFiIiIiEhgDOVERERERAJjKCciIiIiEhhDORERERGRwBjKiYiIiIgExu4r94jFwjytU6jrUt04LrqHY6KbOC5ERPVX138zRSo+CYeIiIiISFBcvkJEREREJDCGciIiIiIigTGUExEREREJjKGciIiIiEhgDOVERERERAJjKCciIiIiEhhDORERERGRwBjKiYiIiIgExlBORERERCQwhnIiIiIiIoHpC11Aa5OVlYX169fj/PnzuHjxIoqLi7F+/Xp069ZN6NJardjYWERGRuLvv/9GWloazM3NERAQgLlz58LV1VXo8lqlCxcuYNWqVbh8+TJycnJgamoKb29vzJo1C4GBgUKXR/esXr0aixcvhre3N6KiooQuh4ioWWMob2LJyclYvXo1XF1d4eXlhbNnzwpdUqu3Zs0axMTEICwsDF5eXsjOzkZ4eDhGjhyJLVu2wMPDQ+gSW52UlBRUVlZizJgxsLGxQUFBAXbs2IGJEydi9erV6NGjh9AltnrZ2dlYuXIljIyMhC6FiKhFEKlUKpXQRbQmhYWFUCgUsLCwwIEDBzBr1izOlAssJiYGnTp1glQqVW+7fv06hg0bhmeeeQZffPGFgNVRtZKSEgwYMACdOnXC999/L3Q5rd67776LtLQ0qFQq5Ofnc6aciOgJcU15EzMxMYGFhYXQZdB9AgMDNQI5ALRt2xaenp5ISkoSqCp6kKGhISwtLZGfny90Ka1ebGwstm/fjvnz5wtdChFRi8FQTlQLlUqF27dv8xcogRUWFuLOnTu4du0alixZgsTERISEhAhdVqumUqnw6aefYuTIkejQoYPQ5RARtRhcU05Ui+3btyMzMxNvvvmm0KW0au+99x727dsHAJBIJHj++ecxffp0gatq3bZt24arV69ixYoVQpdCRNSiMJQTPSApKQkLFixAUFAQRowYIXQ5rdqsWbMwbtw4ZGRkICoqCuXl5VAoFDWWG1HTKCwsxFdffYVXX30Vtra2QpdDRNSicPkK0X2ys7Px2muvwczMDF9//TXEYv6ICMnLyws9evTAc889hx9//BGXLl3iOmYBrVy5EhKJBC+++KLQpRARtThMHET3FBQUYNq0aSgoKMCaNWtgY2MjdEl0H4lEgv79+yM6OhqlpaVCl9PqZGVlYd26dRg/fjxu376N1NRUpKamoqysDAqFAqmpqcjLyxO6TCKiZovLV4gAlJWVYfr06bh+/TrWrl0Ld3d3oUuiWpSWlkKlUqGoqAgGBgZCl9Oq5OTkQKFQYPHixVi8eHGN9/v3749p06bhrbfeEqA6IqLmj6GcWr3KykrMnTsX586dw3fffQd/f3+hS2r17ty5A0tLS41thYWF2LdvHxwcHGBlZSVQZa2Xk5NTrTd3Llu2DMXFxXjvvffQtm3bpi+MiKiFYCgXwHfffQcA6h7YUVFROHPmDORyOSZOnChkaa3SF198gUOHDqFv377Izc3VeAiKsbExBgwYIGB1rdPcuXMhk8kQEBAAGxsbpKenIyIiAhkZGViyZInQ5bVKpqamtf4srFu3Dnp6evw5ISJ6QnyipwC8vLxq3e7o6IhDhw41cTU0adIknDx5stb3OCbC2LJlC6KionD16lXk5+fD1NQU/v7+eOmll9C1a1ehy6P7TJo0iU/0JCLSAoZyIiIiIiKBsfsKEREREZHAGMqJiIiIiATGUE5EREREJDCGciIiIiIigTGUExEREREJjKGciIiIiEhgDOVERERERAJjKCciIsFMmjQJ/fr1E7oMIiLB6QtdABERadfff/+NyZMnP/R9PT09XL58uQkrIiKiR2EoJyJqoYYOHYpevXrV2C4W84+kRES6hqGciKiF6tixI0aMGCF0GUREVA+cLiEiaqVSU1Ph5eWF5cuXY+fOnRg2bBh8fX3Rp08fLF++HBUVFTWOiY+Px6xZs9CtWzf4+vpiyJAhWL16NSorK2vsm52djc8++wz9+/dHp06dEBISghdffBHHjh2rsW9mZibmzZuHLl26wM/PDy+//DKSk5Mb5XMTEekizpQTEbVQJSUluHPnTo3tUqkUJiYm6teHDh1CSkoKJkyYAGtraxw6dAjffvst0tLS8Pnnn6v3u3DhAiZNmgR9fX31vocPH8bixYsRHx+Pr776Sr1vamoqXnjhBeTk5GDEiBHo1KkTSkpKcP78eRw/fhw9evRQ71tcXIyJEyfCz88Pb775JlJTU7F+/XrMnDkTO3fuhJ6eXiN9hYiIdAdDORFRC7V8+XIsX768xvY+ffrg+++/V7+Oj4/Hli1b4OPjAwCYOHEiZs+ejYiICIwbNw7+/v4AgIULF6K8vBwbN26Et7e3et+5c+di586dGD16NEJCQgAAn3zyCbKysrBmzRr07NlT4/pKpVLj9d27d/Hyyy9j2rRp6m2WlpZYtGgRjh8/XuN4IqKWiKGciKiFGjduHMLCwmpst7S01HjdvXt3dSAHAJFIhFdeeQUHDhzA/v374e/vj5ycHJw9exahoaHqQF6974wZM7B3717s378fISEhyM3NxZ9//omePXvWGqgfvNFULBbX6Bbz1FNPAQBu3LjBUE5ErQJDORFRC+Xq6oru3bs/cj8PD48a29q1awcASElJAVC1HOX+7fdzd3eHWCxW73vz5k2oVCp07NixXnXa2tpCJpNpbDM3NwcA5Obm1uscRETNHW/0JCIiQdW1ZlylUjVhJUREwmEoJyJq5ZKSkmpsu3r1KgDA2dkZAODk5KSx/X7Xrl2DUqlU7+vi4gKRSIS4uLjGKpmIqMVhKCciauWOHz+OS5cuqV+rVCqsWbMGADBgwAAAgJWVFQICAnD48GEkJiZq7PvDDz8AAEJDQwFULT3p1asXjhw5guPHj9e4Hme/iYhq4ppyIqIW6vLly4iKiqr1veqwDQDe3t6YMmUKJkyYABsbGxw8eBDHjx/HiBEjEBAQoN7v/fffx6RJkzBhwgSMHz8eNjY2OHz4MI4ePYqhQ4eqO68AwAcffIDLly9j2rRpGDlyJHx8fFBWVobz58/D0dERb7/9duN9cCKiZoihnIiohdq5cyd27txZ63vR0dHqtdz9+vWDm5sbvv/+eyQnJ8PKygozZ87EzJkzNY7x9fXFxo0b8c033+DXX39FcXExnJ2d8dZbb+Gll17S2NfZ2Rlbt27FihUrcOTIEURFRUEul8Pb2xvjxo1rnA9MRNSMiVT8OyIRUauUmpqK/v37Y/bs2ZgzZ47Q5RARtWpcU05EREREJDCGciIiIiIigTGUExEREREJjGvKiYiIiIgExplyIiIiIiKBMZQTEREREQmMoZyIiIiISGAM5UREREREAmMoJyIiIiISGEM5EREREZHA/h94wAJX8n/0pAAAAABJRU5ErkJggg==\n"},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"pURNjYXkVpMd","executionInfo":{"status":"ok","timestamp":1669691832997,"user_tz":420,"elapsed":12,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["# # CELL EXTRACTED FROM SAMPLE NOTEBOOK PROVIDED\n","\n","\n","# # Create sentence and label lists\n","# test_premise = test_df.sentence1.values\n","# test_hypothesis = test_df.sentence2.values\n","# test_labels = test_df.label.values\n","\n","# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","attention_masks = []\n","\n","# For every sentence...\n","for i in tqdm(range(len(test_aug_ip))):\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = roberta_tok.encode_plus(\n","                        test_aug_ip[i],                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 256,           # Pad & truncate all sentences.\n","                        truncation=True,\n","                        padding = \"max_length\",\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","test_labels = torch.tensor(test_labels)\n","\n","# Set the batch size.  \n","batch_size = 32  \n","\n","# Create the DataLoader.\n","prediction_data = TensorDataset(input_ids, attention_masks, test_labels)\n","prediction_sampler = SequentialSampler(prediction_data)\n","prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["a8089b36ab2a4e5aa16eb1785cf88bc9","f97f5a67f69c478fab64bd379e8a2909","1a46b7aab497420bae9f68675487062e","2d88eea003184c06a3764f42ed35ff7a","f36972a695324767a423277ba28663e9","b2c6b0fa29794a86968d71e2b15bc5be","993fde70956345e2a96077cd266d5062","e9464cd4c4b4421daf7885338d2dd749","2effea6bc59644e58c6630b74cdfd9e9","3d51e11a3f014aeaae77027b42a25dc2","e2e2644e5e35474b971a7eb2c744040b"]},"id":"1D4XSJjUV6GU","executionInfo":{"status":"ok","timestamp":1669691833383,"user_tz":420,"elapsed":398,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}},"outputId":"d0fe6642-3600-40fe-e77b-0ea7bbe5b2a1"},"execution_count":41,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1205 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8089b36ab2a4e5aa16eb1785cf88bc9"}},"metadata":{}}]},{"cell_type":"code","source":["# CELL EXTRACTED FROM SAMPLE NOTEBOOK PROVIDED\n","\n","# Prediction on test set\n","\n","print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n","\n","# Put model in evaluation mode\n","model.eval()\n","\n","# Tracking variables \n","predictions , true_labels = [], []\n","\n","# Predict \n","for batch in tqdm(prediction_dataloader):\n","  # Add batch to GPU\n","  batch = tuple(t.to(\"cuda:0\") for t in batch)\n","  \n","  # Unpack the inputs from our dataloader\n","  b_input_ids, b_input_mask, b_labels = batch\n","  \n","  # Telling the model not to compute or store gradients, saving memory and \n","  # speeding up prediction\n","  with torch.no_grad():\n","      # Forward pass, calculate logit predictions.\n","      result = model(b_input_ids, \n","                     token_type_ids=None, \n","                     attention_mask=b_input_mask,\n","                     return_dict=True)\n","\n","  logits = result.logits\n","\n","  # Move logits and labels to CPU\n","  logits = logits.detach().cpu().numpy()\n","  pred_labels = np.argmax(logits, axis=1)\n","  label_ids = b_labels.to('cpu').numpy()\n","  \n","  # Store predictions and true labels\n","  predictions.extend(pred_labels.tolist())\n","  true_labels.extend(label_ids.tolist())\n","\n","print('DONE.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":85,"referenced_widgets":["e71ade5585c64cbb88f0bfd107397c3b","1a354676211f40bf97e00b8ecaba0bde","ed7a43161ac84e469ebd50e244234e31","440555792aa24b148841deebb9711052","abe4f10b68934f13bf93b860ec339cbc","f49e119d9be24ee1ae794b3867562153","c203456115d343989bb4026119c2d81a","f0e5b6600d4e4507b454a169b2c74bac","be8bd107b54544969544dcf547b2f0f3","bf91a4f7e550454592483dbf92c4c40c","8bf2c34ae5e049f696f89e3fb271f7d4"]},"id":"Wy6xeId8V7SR","executionInfo":{"status":"ok","timestamp":1669691842230,"user_tz":420,"elapsed":8852,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}},"outputId":"b6a38a5b-8b89-405c-e7ac-011f2697c1d1"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicting labels for 1,205 test sentences...\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/38 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e71ade5585c64cbb88f0bfd107397c3b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["DONE.\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import classification_report, confusion_matrix\n","print('RoBERTa')\n","print(classification_report(y_true = true_labels, y_pred = predictions))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xtys9uYgWHic","executionInfo":{"status":"ok","timestamp":1669691842230,"user_tz":420,"elapsed":26,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}},"outputId":"5f76915d-b214-42b3-dd59-3a64b7b420e3"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["RoBERTa (standard)\n","              precision    recall  f1-score   support\n","\n","           0       0.34      0.53      0.42       249\n","           1       0.81      0.73      0.77       895\n","           2       0.00      0.00      0.00        61\n","\n","    accuracy                           0.65      1205\n","   macro avg       0.38      0.42      0.39      1205\n","weighted avg       0.67      0.65      0.66      1205\n","\n"]}]},{"cell_type":"code","source":["result_report= classification_report(true_labels, predictions, digits=3, output_dict=True)\n","result_report"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0_rw-HRPWMFH","executionInfo":{"status":"ok","timestamp":1669691842231,"user_tz":420,"elapsed":23,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}},"outputId":"1e07a2a6-1ab3-4bc2-def6-2f202b9e5478"},"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'0': {'precision': 0.34102564102564104,\n","  'recall': 0.5341365461847389,\n","  'f1-score': 0.4162754303599374,\n","  'support': 249},\n"," '1': {'precision': 0.8084054388133498,\n","  'recall': 0.7307262569832402,\n","  'f1-score': 0.767605633802817,\n","  'support': 895},\n"," '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 61},\n"," 'accuracy': 0.6531120331950208,\n"," 'macro avg': {'precision': 0.38314369327966363,\n","  'recall': 0.4216209343893264,\n","  'f1-score': 0.3946270213875848,\n","  'support': 1205},\n"," 'weighted avg': {'precision': 0.6709031139861682,\n","  'recall': 0.6531120331950208,\n","  'f1-score': 0.6561490659030254,\n","  'support': 1205}}"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":[],"metadata":{"id":"kWt4WojXWUBq","executionInfo":{"status":"ok","timestamp":1669691842231,"user_tz":420,"elapsed":20,"user":{"displayName":"Shivam Mathur","userId":"13996464205483377357"}}},"execution_count":44,"outputs":[]}]}